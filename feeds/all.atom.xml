<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Monty's Blog</title><link href="beardedplatypus.github.io/" rel="alternate"></link><link href="beardedplatypus.github.io/feeds/all.atom.xml" rel="self"></link><id>beardedplatypus.github.io/</id><updated>2019-12-27T00:00:00+01:00</updated><entry><title>SonarCloud: Static Code Analysis in a C++ project.</title><link href="beardedplatypus.github.io/sonarcloud-static-code-analysis-in-a-c-project.html" rel="alternate"></link><published>2019-12-27T00:00:00+01:00</published><updated>2019-12-27T00:00:00+01:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-12-27:beardedplatypus.github.io/sonarcloud-static-code-analysis-in-a-c-project.html</id><summary type="html">&lt;p&gt;As part of my &lt;a href="https://github.com/BeardedPlatypus/PacMan"&gt;pacman project&lt;/a&gt;'s Continuous Integration (CI), I have set up 
SonarCloud as a static code analysis tool. This was done to get a bit better
insight in the state of my code base, as well as a way to get feedback and
improve my C++ knowledge â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;As part of my &lt;a href="https://github.com/BeardedPlatypus/PacMan"&gt;pacman project&lt;/a&gt;'s Continuous Integration (CI), I have set up 
SonarCloud as a static code analysis tool. This was done to get a bit better
insight in the state of my code base, as well as a way to get feedback and
improve my C++ knowledge. Because this ended up being slightly more work than 
I initially had hoped, I will use this article to explain how I set up 
SonarCloud in conjunction with my pacman project. Hopefully this will both 
serve as a reminder to myself and a simple tutorial for you.&lt;/p&gt;
&lt;p&gt;For a tl;dr, the DevOps pipeline that is set up can be found &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/7127d4b26988f3442b811a2225583e775bc7b0d9/sonarcloud-pipeline.yml"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;At my current place of work, we use SonarQube to get insight in the quality of
our code. It provides you with a simple, insightful dashboards that highlights
bugs, code smells, code coverage and duplication. This allows developers to 
gain insight in the quality of the code they have committed. To me personally,
I love the way certain bad habits get highlighted, and I get forced to fix 
them. Often, there exists some exotic intricacy within the language I am not 
aware of, or I am using in a wrong way, and SonarQube will highlight it 
mercilessly. This allows me to learn and become a better coder in my opinion, 
in much the same way as I learn from ReSharper suggestions.&lt;/p&gt;
&lt;p&gt;At work, I was not involved in setting this tool up, so I did not have any 
experience, before I set it up for this project. It turned out to be a bit more
of a struggle than I would like to admit, hence this article.&lt;/p&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;It might be useful to give a bit more context in how my project is currently 
set up. This could help evaluate whether the approach I took could be useful 
for your project.&lt;/p&gt;
&lt;p&gt;My pacman clone is developed in (modern) C++, with the help of the SDL2 library
for rendering the sprites. It is build with visual studio 2019 / MSBuild. 
Testing is done with VSTest and the google test adapter. gtest and gmock are 
used to write the unit tests. All of these libraries are installed through 
vcpkg. The whole thing is wrapped into an installer with the help of WiX.&lt;/p&gt;
&lt;p&gt;On the CI side of things, I use Azure DevOps to automate my build and test 
processes. So far, I have been positively surprised by Azure DevOps, and the 
convenience of running these things in the cloud is great. I use boards to 
track my work items, and pipelines to run my build processes. The repository is
hosted on GitHub, since I use that as my portfolio.&lt;/p&gt;
&lt;h1&gt;Setting up SonarCloud&lt;/h1&gt;
&lt;h2&gt;Pre-requisites&lt;/h2&gt;
&lt;p&gt;I am going to assume that the you have set up the following accounts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SonarCloud: https://sonarcloud.io/&lt;/li&gt;
&lt;li&gt;Azure DevOps: https://azure.microsoft.com/en-us/services/devops/&lt;/li&gt;
&lt;li&gt;A online repository, from a service like Azure Repos, GitHub, GitLab, 
  BitBucket etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am also going to assume you are vaguely familiar with Azure Pipelines. I will
try to explain the different steps added to my pipelines to the best of my 
abilities, but I might gloss over steps not related to SonarCloud. I have also
used a bit of python to glue everything together, so be prepared for that too.
Finally, as always with my articles, take it with a bit of salt. I am by no 
means an expert in any of this, so there might be better ways to do some of
these steps. If you find something that works better, by all means go for it!&lt;/p&gt;
&lt;h2&gt;A basic setup&lt;/h2&gt;
&lt;p&gt;I started off by following the basic SonarCloud / Azure DevOps tutorial found
&lt;a href="https://docs.microsoft.com/en-us/labs/devops/sonarcloudlab/index"&gt;here&lt;/a&gt;.
However, I ran into some problems due to the fact I am using C++. So the 
following text will be significantly inspired by the previously mentioned 
tutorial, however, it is adapted to how I got it to work with C++.&lt;/p&gt;
&lt;p&gt;With that out of the way, let's get started, and set up our initial SonarCloud
pipeline.&lt;/p&gt;
&lt;h3&gt;Adding the SonarCloud extension&lt;/h3&gt;
&lt;p&gt;Navigate to the &lt;a href="https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarcloud"&gt;SonarCloud extension&lt;/a&gt;
on the Visual Studio Marketplace, and install it into your project. This 
will add the required tasks into your online pipeline editor, and will save
us from a bunch of fiddling with the command line.&lt;/p&gt;
&lt;h3&gt;Creating a new pipeline&lt;/h3&gt;
&lt;p&gt;Once you have the extension installed, there are two roads you could take.
Either you could integrate the SonarCloud steps into an existing pipeline,
possibly as a separate stage or job, or you could add an additional 
pipeline. I opted for the latter for the sake of simplicity, but do not let
that stop you from integrating it with an existing pipeline.&lt;/p&gt;
&lt;p&gt;I created a new "Starter pipeline", using my pacman repository as the source,
and called it &lt;code&gt;sonar-cloud-pipeline.yml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;At the time of writing, this leads to the following yaml file:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/a7d555bbaeb68791cf8646d812b10748.js"&gt;&lt;/script&gt;

&lt;p&gt;The current content is not particularly relevant for our use case, so I
replaced it with the basic build steps for building my pacman application:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/5d417571a1ff3c00b4a046366745e9a6.js"&gt;&lt;/script&gt;

&lt;h3&gt;Adding the SonarCloud tasks&lt;/h3&gt;
&lt;p&gt;SonarCloud will analyse your solution by applying various metrics to
find problems with your code. It does so by static analysis, and it
will gather data while you compile your program. In order to do so
we need to first configure SonarCloud to analyse our compile process.
Then, we need to compile our program. The results of this can then be
used by SonarCloud to analyse our project. Finally, the results of the
analysis need to be pushed to the SonarCloud server, such that they become
available in our SonarCloud dashboard.&lt;/p&gt;
&lt;p&gt;This means we will have to add the following three tasks to our pipeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SonarCloudPrepare@1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SonarCloudAnalyze@1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SonarCloudPublish@1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Where &lt;code&gt;SonarCloudPrepare@1&lt;/code&gt; will be placed before our build process, and the
other two will be placed after. &lt;/p&gt;
&lt;h3&gt;SonarCloud Prepare&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;SonarCloudPrepare@1&lt;/code&gt; task will require some some setting up, which the
assistant will walk you through. First, select the "Prepare Analysis 
Configuration". We will see several options we need to configure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SonarCloud Service Endpoint&lt;/li&gt;
&lt;li&gt;Organization&lt;/li&gt;
&lt;li&gt;Choose the way to run the analysis&lt;/li&gt;
&lt;li&gt;Project Key&lt;/li&gt;
&lt;li&gt;Project Name&lt;/li&gt;
&lt;li&gt;Project Version&lt;/li&gt;
&lt;li&gt;Additional Properties (under advanced)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Starting off with the SonarCloud Service Endpoint. We will need to configure
the end point within our SonarCloud project, and link it to our Azure DevOps
project. First we will generate a SonarCloud token.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Navigate to your project on &lt;a href="www.sonarcloud.io"&gt;sonarcloud.io&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Go to "My account" (under your profile avatar in the top right corner).&lt;/li&gt;
&lt;li&gt;Go to the "Security" tab, between "Profile" and "Notifications".&lt;/li&gt;
&lt;li&gt;Under "Generate Tokens", add a new recognisable name. This name will not be
   used, but it does serve as a reminder for what the token was generated, such
   that you know whether you want to keep it later, or revoke it. As such, I 
   would recommend giving it a readable name, in my case it is called "PacMan 
   Azure DevOps".&lt;/li&gt;
&lt;li&gt;Press the "Generate" button and copy the token. (Note, by closing this tab
   you will not be able to copy it anymore, and you will have to revoke the 
   previous tab, I would recommend either putting it in a notepad temporarily
   or leaving this tab open until you are done setting this up.)&lt;/li&gt;
&lt;li&gt;With the token generated, go to your Azure DevOps project settings. (This can
   be done by selecting the little cog icon next to your Azure project name).&lt;/li&gt;
&lt;li&gt;Select the "Service connections" link under "Pipelines".&lt;/li&gt;
&lt;li&gt;Press "New service connection" in the top right corner.&lt;/li&gt;
&lt;li&gt;Find and click the "SonarCloud" entry in the list and press "Next".&lt;/li&gt;
&lt;li&gt;Add the token in the "SonarCloud Token" field and press verify.&lt;/li&gt;
&lt;li&gt;Fill in a readable name in the "Service connection name", this is the name
   we will add to "SonarCloud Service Endpoint" field in our yaml file.&lt;/li&gt;
&lt;li&gt;Optionally add a description.&lt;/li&gt;
&lt;li&gt;Press "Verify and save". Now we are ready to add this to our yaml.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With the SonarCloud Service Endpoint configured, go ahead and add the name
you provided in step 11 within the field of "SonarCloud Service Endpoint".&lt;/p&gt;
&lt;p&gt;In the "Organization" and "Project Key" fields, add your SonarCloud 
"Organization Key" and "Project Key" respectively. These can be found in the 
second column of your SonarCloud project dashboard.&lt;/p&gt;
&lt;p&gt;Since I am integrating it with MSBuild, the scanner mode is selected to be
"MSBuild". "Project Name" is set to the same as my project, and for the
sake of simplicity I have set my "Project Version" to 1.0, though you can
set this to the respective version of your software, and it will be displayed
correctly in your project dashboard.&lt;/p&gt;
&lt;p&gt;Finally press add, to add this task to your pipeline yaml. It should be 
before the actual VSBuild step.&lt;/p&gt;
&lt;h3&gt;SonarCloud Analyse and Publish&lt;/h3&gt;
&lt;p&gt;Next we will add the &lt;code&gt;SonarCloudAnalyze@1&lt;/code&gt; and &lt;code&gt;SonarCloudPublish@1&lt;/code&gt; tasks
after our VSBuild step. Find the "Run Code Analysis" and "Publish Quality
Gate Result" tasks in your assistant, and add them to your yaml. I did not
modify the polling time out myself, and just left it at 5 minutes.&lt;/p&gt;
&lt;p&gt;The pipeline will now look like this:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/15124ef12556e4c660fccf263774d2e4.js"&gt;&lt;/script&gt;

&lt;h3&gt;Adding the build wrapper&lt;/h3&gt;
&lt;p&gt;In an ideal world, this should be enough to get SonarCloud to work. 
Unfortunately, this being a C/C++ project, we need to do some additional 
work. When this pipeline is run it gives an error containing the following
statement:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/2a9b78e380a6fbe37c42eac36ce34d57.js"&gt;&lt;/script&gt;

&lt;p&gt;In order for it to work, we will need to wrap our MSBuild process in the 
build wrapper process. The executable to do this can be obtained from 
the SonarCloud website &lt;a href="https://sonarcloud.io/static/cpp/build-wrapper-win-x86.zip"&gt;here&lt;/a&gt;.
I opted to put this directly into my repository, because I am lazy, and had
some trouble getting it to download correctly as a build step. There is nothing
stopping you from adding it as a download step instead though.&lt;/p&gt;
&lt;p&gt;Either way, after obtaining it you should have a path to the executable. For 
the sake of convenience let's wrap this in a variable, add the following line
to your variables section of your yaml:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;  buildWrapperExe: &amp;#39;$(Build.SourcesDirectory)/tools/build-wrapper-win-x86-64.exe&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can also add our future output directory, as mentioned in the error message,
as a variable, such that we only have to define it once:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;  buildWrapperOutputDir: &amp;#39;$(Build.SourcesDirectory)/build_wrapper_output_directory&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With that out of the way, the next step is to modify our &lt;code&gt;VSBuild&lt;/code&gt; step. Unfortunately
our regular &lt;code&gt;VSBuild&lt;/code&gt; step does not have a way to wrap it in our build wrapper, or 
I have not found a way to do this. Instead, I have changed the &lt;code&gt;VSBuild&lt;/code&gt; task to 
a power shell task, and defined the command myself. It is not pretty but it works.&lt;/p&gt;
&lt;p&gt;The new command becomes:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/6a11fc85f5bf2514095b929eb22642d9.js"&gt;&lt;/script&gt;

&lt;p&gt;Let's break down what happens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First we define call our build wrapper executable stored in &lt;code&gt;buildWrapperExe&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;We set the output path of any results to the &lt;code&gt;buildWrapperOutputDir&lt;/code&gt; we defined earlier.&lt;/li&gt;
&lt;li&gt;We call the MSBuild exe stored in &lt;code&gt;msBuildExe&lt;/code&gt;, this is the regular MSBuild stored on the Azure agent.&lt;/li&gt;
&lt;li&gt;We make it compile our solution, and set the configuration and platform similarly to a regular &lt;code&gt;VSBuild&lt;/code&gt; task.&lt;/li&gt;
&lt;li&gt;We also specified the option &lt;code&gt;-nologo&lt;/code&gt; to skip printing the logo, such that our output log stays a bit clean.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the build wrapper configured, the only thing we need to set is the build 
wrapper output directory within our &lt;code&gt;SonarCloudPrepare&lt;/code&gt; task. This will allow
the &lt;code&gt;SonarCloudAnalyze&lt;/code&gt; step to pick up on our results, and actually produce
the right results. We do this by adding the following line to the additional 
properties of SonarCloud:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sonar.cfamily.build-wrapper-output=$(buildWrapperOutputDir)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lastly, I have set up my SonarCloud pipeline to run once every three hours if
a commit has taken place. This will ensure I am not running my pipeline 
unnecessarily. If I do happen to need immediate feedback I tend to kick off my 
pipeline by hand anyway. In order to do this, I changed the beginning of my
pipeline yaml to the following:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/4c8cc75f6ac2b4476b08910e2fca6d1a.js"&gt;&lt;/script&gt;

&lt;p&gt;If you have followed along diligently and I did not make any mistake, you 
should have the following yaml code:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/5d884475fc5949fa384105077d24b62b.js"&gt;&lt;/script&gt;

&lt;p&gt;With all that out of the way we should have our basic SonarCloud pipeline up
and running, and we should be able to inspect the results in our SonarCloud
project dashboard. Up next, we will take a look how to connect our final metric,
code coverage.&lt;/p&gt;
&lt;h2&gt;Adding code coverage&lt;/h2&gt;
&lt;p&gt;The last metric to set up within SonarCloud is the code coverage. I will not go
into detail about how to unit test, or why it is a good thing, enough articles
are written on these topics already, but I will add that if you are not writing
unit tests, I wholeheartedly encourage you to start doing so. If you are not
interested in the code coverage, you already got everything set up to start
using SonarCloud to start improving the code smells, and you can freely skip
this section.&lt;/p&gt;
&lt;p&gt;Within SonarCloud we can display the code coverage metric. Once set up, 
SonarCloud will show you the overall code coverage of your solution, as well as
the coverage on newly added line, giving you a good sense of how well tested
your new code is. Furthermore, it provides a convenient interface to show which
parts of the code are untested, and let's you sort files containing uncovered 
lines in greater detail. A very useful feature in my opinion.&lt;/p&gt;
&lt;p&gt;As mentioned previously, within the pacman project I use gtest / gmock to do my
testing in combination with the google test adapter and VSTest. When running 
the VSTest task on Azure Pipelines, you can enable measuring code coverage. 
This will add a &lt;code&gt;.coverage&lt;/code&gt; file somewhere on your agent. You could use this
&lt;code&gt;.coverage&lt;/code&gt; file within visual studio to show the uncovered pieces of code.
With a bit of tweaking, we can also use this data within SonarCloud.
Unfortunately however, the &lt;code&gt;.coverage&lt;/code&gt; file is not supported out of the box,
and we will need to export it to an &lt;code&gt;.xml&lt;/code&gt; file, before it will play nice.&lt;/p&gt;
&lt;h3&gt;Producing a .coverage file&lt;/h3&gt;
&lt;p&gt;The first step into getting the code coverage set up in SonarCloud, is ensuring
the &lt;code&gt;.coverage&lt;/code&gt; gets produced. As mentioned before, we can configure a VSTest
task to produce these files. Within my pacman project, I already have a CI 
pipeline in place that runs my test suite. Instead of rerunning the whole test
suite just to produce the code coverage, I figured it would be less wasteful to
reuse the data gathered during this CI pipeline. As such, the following text 
will assume you have two pipelines, one CI and one SonarCloud pipeline. The 
SonarCloud pipeline will reuse the artefacts from the CI pipeline. It should 
only be a minor inconvenience to modify the SonarCloud pipeline, to run the
VSTest itself. With that out of the way, let's set up the &lt;code&gt;.coverage&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;We can enable the code coverage by adding the following option to our VSTest task:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;codeCoverageEnabled&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will ensure our &lt;code&gt;.coverage&lt;/code&gt; file gets produced. With the current iteration
of the VSTest task this file will be placed in the test results folder, located
in the TEMP folder of the Azure Agent. This location has changed in between
versions of the VSTest task already, therefor it would not necessarily be smart
to rely on an absolute path. Instead, we will configure our VSTest task to output
the &lt;code&gt;.coverage&lt;/code&gt; file in a specific location. To do so we need to create a 
&lt;code&gt;.runsettings&lt;/code&gt; that specifies the output location, as shown below:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/7bfdab6e73c1fc3718ee20fce9a6841f.js"&gt;&lt;/script&gt;

&lt;p&gt;Where &lt;code&gt;some/Directory&lt;/code&gt; is the path where the coverage files will be placed in.
In order to keep all of this as flexible as possible, I opted to generate this
&lt;code&gt;.runsettings&lt;/code&gt; file during execution with a python script, which takes the path
it will generate as an argument. This way we do not need to make any 
assumptions about the file system, and instead can set this in our pipeline yaml.&lt;/p&gt;
&lt;p&gt;The script to do this can be located &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/64ecbff3512e6205a95b02712f0ad2f73e37d978/tools/location_runsettings.py"&gt;here&lt;/a&gt;. 
I will not go over the script line by line, I hope it is mostly 
self-explanatory. But I will explain the rough idea. The script itself takes
two arguments, first the path at which we want to construct the new 
&lt;code&gt;.runsettings&lt;/code&gt; file, and the path we want to output the &lt;code&gt;.coverage&lt;/code&gt; file to. 
These arguments are parsed with the help of the argparse library, in the 
&lt;code&gt;parse_arguments&lt;/code&gt; function. Within the &lt;code&gt;run&lt;/code&gt; function, we first construct
the output directory and the parent directory of the &lt;code&gt;.runsettings&lt;/code&gt; file, if
they do not exist yet. Lastly we generate the &lt;code&gt;.runsettings&lt;/code&gt; file at the 
specified path with the use of the &lt;code&gt;RUNSETTINGS_TEMPLATE&lt;/code&gt; in the &lt;code&gt;generate_runsettings&lt;/code&gt;
function.&lt;/p&gt;
&lt;p&gt;We can integrate this script by adding the following two tasks to our pipeline
yml anywhere before the VSTest task:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/3f5d0f1d88d90f542da4ca153761b70a.js"&gt;&lt;/script&gt;

&lt;p&gt;This will first set up the required Python 3 interpreter, and then execute the 
python script linked earlier. The mentioned arguments are stored in the 
variables &lt;code&gt;codeCoverageLocationRunsettings&lt;/code&gt; and &lt;code&gt;testResults&lt;/code&gt;. These have been
defined in the variables section of our pipeline yaml, and will be reused in
subsequent steps.&lt;/p&gt;
&lt;p&gt;Finally, we need to modify our VSTest task slightly to make use of our generated
&lt;code&gt;.runsettings&lt;/code&gt; file. As part of the &lt;code&gt;inputs&lt;/code&gt; of the VSTest add the following line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;runSettingsFile: '$(codeCoverageLocationRunsettings)'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will ensure that the &lt;code&gt;.coverage&lt;/code&gt; files are generated in &lt;code&gt;testResults&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Passing the .coverage files between pipelines&lt;/h3&gt;
&lt;p&gt;This section deals with interaction between the two pipelines, if you are 
running the VSTest task within your SonarCloud pipeline, you can safely skip
this section.&lt;/p&gt;
&lt;p&gt;Now that we have our &lt;code&gt;.coverage&lt;/code&gt; files generated in a known location, we can
publish them as pipeline artefacts, and download them in the SonarCloud 
pipeline. Publishing files as an artefact is done through the 
&lt;code&gt;PublishPipelineArtifact&lt;/code&gt; task, or "Publish Pipeline Artifacts" in your Azure
Pipelines assistant. Go ahead and select it from the list in your assistant.
We have the following fields that we can configure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File or directory path&lt;/li&gt;
&lt;li&gt;Artifact name&lt;/li&gt;
&lt;li&gt;Artifact publish location&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the directory path we want to use the &lt;code&gt;testResults&lt;/code&gt; variable. The name
can be anything you like, however we will use this name within the SonarCloud
pipeline, so I would not recommend going all out on it. Lastly, the Artifact 
publish location should be set to "Azure Pipelines" (unless you have a really
good reason to upload it to a fileshare, then knock yourself out).&lt;/p&gt;
&lt;p&gt;This should lead to the following code (note, I added a simple display name
to make my build steps look nice in the log):&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/feda76e5c449bb37a50d0a90047a3bb7.js"&gt;&lt;/script&gt;

&lt;p&gt;Next, we will download the coverage pipeline artefact within our SonarCloud
pipeline. This can be done with the &lt;code&gt;DownloadPipelineArtifact&lt;/code&gt; task, or 
"Download Pipeline Artifacts" in your assistant. We have a bunch of options
to configure here.&lt;/p&gt;
&lt;p&gt;First set the "Download artifacts produced by" to "Specific run", 
which will open up some additional options. The project should be set
to the project that contains your CI pipeline, and the "Build pipeline"
should be set to this specific pipeline. In my case these are "PacMan"
and "Build and Test PacMan" respectively. For "Build version to download"
pick "Latest". You could add a specific tag that should be present to
use to select a specific run, but I have not bothered with this.&lt;/p&gt;
&lt;p&gt;Finally we need to set the "Artifact name", "Matching patterns", and
the "Destination directory". For "Artifact name" pick the name that
you gave the artifact in the previous step (&lt;code&gt;coverage&lt;/code&gt; in the snipped above).
Since we are only interested in the &lt;code&gt;.coverage&lt;/code&gt; file, I have specified 
my "Matching patterns" to &lt;code&gt;**/*.coverage&lt;/code&gt;, this will look recursively
in all the folders of my artefact for any file ending with &lt;code&gt;.coverage&lt;/code&gt;.
As a final step, download the files somewhere on your agent. In my case
I put it in a variable called &lt;code&gt;coverageDownloadLocation&lt;/code&gt;. This should 
put a task in your yaml comparable to:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/322a9de24d68c20e9f12cf1d2451ca71.js"&gt;&lt;/script&gt;

&lt;p&gt;Next up, we will convert the &lt;code&gt;.coverage&lt;/code&gt; file to &lt;code&gt;.xml&lt;/code&gt; and feed it into
the SonarCloud analysis.&lt;/p&gt;
&lt;h3&gt;Converting the .coverage file&lt;/h3&gt;
&lt;p&gt;Converting the &lt;code&gt;.coverage&lt;/code&gt; files to &lt;code&gt;.xml&lt;/code&gt; is a reasonably easy process, once
you have figured out how to do it. The path to figuring it out though, is
painful and filled with perils, so hopefully you can learn from my mistakes
and it will be a breeze for you. First and foremost let me state, that if you
want to use paths with spaces in your python and command line scripts, make sure
you use double quotes, &lt;code&gt;"&lt;/code&gt;, and not single quotes, &lt;code&gt;'&lt;/code&gt;. Yes ... it took me longer
than I would like to admit to figure that out. With that out of the way, let's
look at how we can convert &lt;code&gt;.coverage&lt;/code&gt; files in to something usable by SonarCloud.&lt;/p&gt;
&lt;p&gt;If my understanding is correct, the &lt;code&gt;.coverage&lt;/code&gt; is basically a binary blob of
code coverage information, which can be used by Visual Studio to give you an
indication of your code coverage. Unfortunately, it does not work out of the 
box for SonarCloud. This means we need to convert it to an &lt;code&gt;.xml&lt;/code&gt; file that is
usable. There are various ways of doing this, but the easiest I have found is 
to use the &lt;code&gt;codecoverage.exe&lt;/code&gt; provided with Visual Studio Enterprise, i.e. the
Visual Studio version that is installed on the Azure agents.&lt;/p&gt;
&lt;p&gt;When we run the following command, it will convert the &lt;code&gt;.coverage&lt;/code&gt; into an &lt;code&gt;.xml&lt;/code&gt;
file:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/8970b5d2b2588d0df38bcc3f9ad097d2.js"&gt;&lt;/script&gt;

&lt;p&gt;Where input and output can basically be any name you want it to be. &lt;/p&gt;
&lt;p&gt;Because I did not want to hard code the location of the &lt;code&gt;codecoverage.exe&lt;/code&gt;,
and I do not know the &lt;code&gt;.coverage&lt;/code&gt; file names without running actually running
the pipeline, I ended up writing another python script to dynamically resolve
these things. The script can be found &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/3d723576abfbf06da38007984b37b9696efd89a6/tools/convert_coverage.py"&gt;here&lt;/a&gt;.
Again, I will not go over the script line by line, but I will explain the rough
set up. The script takes one argument, the folder in which the &lt;code&gt;.coverage&lt;/code&gt; files
are located. It then resolves the &lt;code&gt;codecoverage.exe&lt;/code&gt; path by searching for it in
the Visual Studio folder of the agent. It will then copy the &lt;code&gt;.coverage&lt;/code&gt; files from 
the specified path to the current working directory. Lastly, it will convert the
recently copied files from &lt;code&gt;.coverage&lt;/code&gt; to &lt;code&gt;.xml&lt;/code&gt; using the &lt;code&gt;codecoverage.exe&lt;/code&gt;.
Once done, the current working directory should contain the relevant &lt;code&gt;.xml&lt;/code&gt; files
(and the original &lt;code&gt;.coverage&lt;/code&gt; files). &lt;/p&gt;
&lt;p&gt;This script is ran in the same way as before, by adding two python tasks (after
the download pipeline artifacts task):&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/baa6114cb11198c6ba6f5dc4f8b3ca74.js"&gt;&lt;/script&gt;

&lt;p&gt;We set up the argument and the working directory with the appropriate variables
again defined in the variable section of the yaml. If you are interested in 
seeing the output, you could publish the defined working directory as an artefact,
such that they can be downloaded and inspected.&lt;/p&gt;
&lt;h3&gt;Modifying the SonarCloud tasks&lt;/h3&gt;
&lt;p&gt;The final step to wrap up our SonarCloud setup, is to use the newly generated
&lt;code&gt;.xml&lt;/code&gt; files within our analyses. For this we need to add one more line to our
&lt;code&gt;extraProperties&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sonar.cfamily.vscoveragexml.reportsPath=$(coverageFiles)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Where &lt;code&gt;coverageFiles&lt;/code&gt; is defined as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;coverageFiles: &amp;#39;$(coverageOutputLocation)\*.xml&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Which says all the &lt;code&gt;.xml&lt;/code&gt; files within the location where we generated our &lt;code&gt;.xml&lt;/code&gt;
files. This should ensure that SonarCloud takes into account the code coverage,
and you can keep an eye on maintaining that 80%+ metric!&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This guide turned out to be slightly longer than I originally intended, but if
you followed along, and I did not make any mistakes, you should have a pipeline
looking similar to &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/7127d4b26988f3442b811a2225583e775bc7b0d9/sonarcloud-pipeline.yml"&gt;my SonarCloud pipeline&lt;/a&gt;. Which should provide you with a dashboard similar to
&lt;a href="https://sonarcloud.io/dashboard?id=BeardedPlatypus_PacMan"&gt;my pacman project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope this made the process of setting up SonarCloud for a C++ project slightly
easier for you. Thank you for reading! And if you have any comments, suggestions, 
or questions, let me know!&lt;/p&gt;</content></entry><entry><title>TeamCity: Adding a custom report to your build configuration</title><link href="beardedplatypus.github.io/teamcity-adding-a-custom-report-to-your-build-configuration.html" rel="alternate"></link><published>2019-08-03T00:00:00+02:00</published><updated>2019-08-03T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-08-03:beardedplatypus.github.io/teamcity-adding-a-custom-report-to-your-build-configuration.html</id><summary type="html">&lt;p&gt;Recently, I took some time to add a bit of custom reporting to the teamcity 
project we use at work. I did not have much experience with this before, and
honestly, I was quite surprised with the ease to do so. As a reference for 
myself, and hopefully for you â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, I took some time to add a bit of custom reporting to the teamcity 
project we use at work. I did not have much experience with this before, and
honestly, I was quite surprised with the ease to do so. As a reference for 
myself, and hopefully for you as well, in this short article I will detail how I
achieved this.&lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;To give a little bit of background, at the time of writing, I work at Deltares,
a knowledge institute on Water. I work on one of the GUIs for our water 
modelling software. We use TeamCity on our build server. The TeamCity project 
contains a bunch of configurations doing different tests and builds our 
installers.&lt;/p&gt;
&lt;p&gt;One of these configurations is our Acceptance Tests configuration. This
configuration runs a bunch of models, made within deltares, that our considered
representative of models that can be made. As such, if the software runs 
correctly for these models, it should run correctly for all models.
The test configuration is set up to run a set of NUnit tests that load these
models, does a few checks and runs the models. Arguably this is not an ideal
set up, but it is the process we have at the moment. &lt;/p&gt;
&lt;p&gt;Each model run produces a log file, that describes what has happened, as well as
any warnings and errors. This file is of interest when these acceptance models
start failing. However, the current set up removes all of these files. We want
to be able to inspect these files, to check them for any warnings or errors that
might point to mistakes in our code (or the kernel code).&lt;/p&gt;
&lt;p&gt;A first step to achieve that, would be to save these files in a separate 
artifact. Which allows us to download them, and inspect them. But why stop 
there? We could easily extend this, to allow us to inspect the files from within
TeamCity, which lowers the barrier to do so, quite a bit. We can do so with 
custom reports, hence this article.&lt;/p&gt;
&lt;h1&gt;Bring out the custom reports!&lt;/h1&gt;
&lt;h2&gt;What do we need?&lt;/h2&gt;
&lt;p&gt;A custom report is basically an additional tab, in which we can display 
additional information, which is produced as part of our build procedure. This
can be anything, really. It can be used to track performance times, it can be 
used to build a custom coverage tool. All we need to add this custom report to
our TeamCity configuration, is an html file. This html file will be hosted in
the TeamCity report tab, &lt;a href="https://confluence.jetbrains.com/display/TCD10/Including+Third-Party+Reports+in+the+Build+Results"&gt;see this documentation&lt;/a&gt;.
You can even put your html file in an archive like zip, and just refer to it.
Something we will do. &lt;/p&gt;
&lt;p&gt;In order to make this report available to our tab, we do need to add it to our
artifacts. As such, the only thing you need is an html file that is published 
as an artifact.&lt;/p&gt;
&lt;h2&gt;Optionally adding an additional build step&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Feel free to skip this part if you do not need to add a new build step that executes a python tool&lt;/em&gt;
As mentioned before, the html file should be produced as part of the build
process. If none is produced at the moment, it might be necessary to add another
build step to your configuration, which is responsible for building the actual 
report.&lt;/p&gt;
&lt;p&gt;In my case, the tests produce a bunch of log files, one per model run. These
are saved within the check-out folder, such that they will not be immediately
deleted. However, no report html is generated automatically. To do this, I have
written a small python script, that collects the content of the log files and 
stuffs them inside a simple html file. This html file is the one we want to 
publish. Lastly, the script zips the whole set of log files and the index
file into a single zip, for easy download.&lt;/p&gt;
&lt;p&gt;In order to execute this script, a build step is added to the configuration: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First navigate to the build configuration, in which we want to produce the
     report. Press the &lt;em&gt;Edit Configuration Settings&lt;/em&gt; link in the top right corner
     next to the &lt;em&gt;run&lt;/em&gt; and &lt;em&gt;actions&lt;/em&gt; button. From here, select the &lt;em&gt;Build Steps&lt;/em&gt;
     link on the left hand side of the screen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We are presented with several buttons that allow us to modify our build
     configuration. We want to press &lt;em&gt;Add build step&lt;/em&gt; to create our new build
     step at the end of our configuration. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You are presented with a wizard to set up your build step. In our case, we
     want to execute a python script, which we will do from the Command Line, 
     thus we select &lt;em&gt;Command Line&lt;/em&gt; as our runner type, did not see that coming
     did you? &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choose an appropriate &lt;em&gt;Step name&lt;/em&gt;, this will show up in the build steps
     page we were on earlier. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In our case we want to execute the python script regardless of whether the
     test runs were successfull, so instead of &lt;em&gt;If all previous steps finished successfully&lt;/em&gt;
     we can select, &lt;em&gt;Even if some of the previous steps failed&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can leave the &lt;em&gt;Working Directory&lt;/em&gt; empty if you are running from the
   check-out folder, otherwise you want to set the folder in which you want
   to execute your command line script. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can also leave the &lt;em&gt;Custom script&lt;/em&gt; bit, and move on to filling in the
     build script content.  &lt;/p&gt;
&lt;p&gt;On our build server we have installed &lt;code&gt;conda&lt;/code&gt;, which we will use to quickly
 generate a python3 environemnt, which we will use to execute the script.
 Then we will run the script, and finally we will remove the environment 
 again, because it is always good to clean up after yourself.&lt;br&gt;
 This leads to the following script:  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;create&lt;/span&gt; &lt;span class="n"&gt;-y&lt;/span&gt; &lt;span class="n"&gt;-n&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;5&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;activate&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;path/to/your/script.py&amp;quot;&lt;/span&gt; &lt;span class="no"&gt;[withOptionalArguments]&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;deactivate&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;remove&lt;/span&gt; &lt;span class="n"&gt;-y&lt;/span&gt; &lt;span class="n"&gt;-n&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-all&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now got our reporting tool set up, which will produce our output somewhere
in our check-out folder (hopefully).&lt;/p&gt;
&lt;h2&gt;Adding the report to the artifacts&lt;/h2&gt;
&lt;p&gt;Assuming we have our reports being generated somewhere within the check-out 
folder. We will have to add them to our artifacts. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First navigate to the build configuration to which we want to add our report
     tab. Then press &lt;em&gt;Edit Configuration Settings&lt;/em&gt; next to the &lt;em&gt;Run&lt;/em&gt; and &lt;em&gt;Actions&lt;/em&gt;
     buttons.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the page that opens there should be an &lt;em&gt;Artifact paths&lt;/em&gt; section. We can 
     add the path to our report here, such that it gets released as an artifact.
     The given path should be relative to the check-out folder.&lt;br&gt;
     In our case, the report is made in an &lt;em&gt;Artifacts&lt;/em&gt; folder, and is called
     &lt;em&gt;dia_report.zip&lt;/em&gt; (naming has never been one of my strong suits). Thus our
     artifact becomes.  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Artifacts\dia_report.zip&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;If you already have a run that produced the report, you can also press the
 little tree button next to the text field, to select it, producing the 
 correct path.  &lt;/p&gt;
&lt;p&gt;With that done, you should see your report in the next run as an artifact.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Adding a custom build report&lt;/h2&gt;
&lt;p&gt;The last step is adding the actual custom report tab to the build configuration.
This is not done within the build configuration, something I found a bit counter
intuitive, but instead should be done at the project root. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;&amp;lt;root project&amp;gt;&lt;/code&gt; and select &lt;em&gt;Edit Project Settings&lt;/em&gt; in the 
     top right corner.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;em&gt;Report Tabs&lt;/em&gt; page through the menu on your left hand side.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are two options, you can create a new project report tab, or a build
     report tab. Project report tabs will show on the project, and use the 
     artifacts produced by one of the build configurations within the project.
     The build tab is what we want. It allows us to set a path to a report html.
     Any build configuration that contains an html file within its artifacts at 
     this specific path, will have this build tab.&lt;/p&gt;
&lt;p&gt;As such, press the &lt;em&gt;Create new build report tab&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now set the &lt;em&gt;Tab Title&lt;/em&gt; and the &lt;em&gt;Start page&lt;/em&gt; of your report html. 
     Press save, and voila! We should have ourselves a custom report tab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Within this article we added a simple custom report tab to one of our TeamCity
build configurations. We can use this to provide easily provide additional 
test information directly within our build server. The process itself is 
rather painless, and for the most part intuitive. All things considered, 
I am really happy how this turned out, and I hope it helps you in your 
process as well.&lt;/p&gt;
&lt;p&gt;Hopefully see you next time!&lt;/p&gt;</content></entry><entry><title>Setting up Continuous Delivery for your static website.</title><link href="beardedplatypus.github.io/setting-up-continuous-delivery-for-your-static-website.html" rel="alternate"></link><published>2019-07-21T00:00:00+02:00</published><updated>2019-07-21T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-07-21:beardedplatypus.github.io/setting-up-continuous-delivery-for-your-static-website.html</id><summary type="html">&lt;p&gt;In this article we will take a short look how to set up continuous delivery for
a simple static website (my own, woo!) with Azure DevOps. Once set up, any 
commit to both content and the theme should trigger the right builds that end up
building and pushing the changes â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this article we will take a short look how to set up continuous delivery for
a simple static website (my own, woo!) with Azure DevOps. Once set up, any 
commit to both content and the theme should trigger the right builds that end up
building and pushing the changes to a github pages website. For my own website
I use pelican, however, the content in this article should be easily adjustable
to any static website!&lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Lately, I have been wanting to start writing and posting some blog articles 
again. Having an active blog has been something I want for quite a while (I 
think my original github pages was created afew years ago), however I never took
the time to properly finish any of the articles, as polishing my own personal 
projects has never been a strong suit of mine. &lt;/p&gt;
&lt;p&gt;These past few weeks I have been working on some small personal projects that I
want to document in some fashion, such that I can understand what I did in the
future. I figured this would be an excellent opportunity to create some blog 
articles that are worth sharing. &lt;/p&gt;
&lt;p&gt;When I looked at this dusty bit of webspace, I noticed however, that it had not
aged as well as I had hoped. So as would be expected from my procrastinating 
nature, I decided to first dust it off, give it a lick of paint, before doing 
the thing I actually want to do, which is write the blog articles.&lt;/p&gt;
&lt;p&gt;As part of the dusting off, I figured I would automate some steps that felt 
like a drag. Because the website is a generated static website, whenever I made 
a change to either the the theme or the content, I would need to run all the 
compilation steps by hand, and then push the results to my github pages 
repository. Lazy as I am, this cannot be of course. &lt;/p&gt;
&lt;p&gt;As I have been working with Azure DevOps lately in some other personal projects, 
I figured it would be a good choice to automate the compilation with. These 
build steps can then be executed as part of a build pipeline running on the 
servers of microsoft. And because of that idea, you can now read this article!&lt;/p&gt;
&lt;h1&gt;Project Configuration&lt;/h1&gt;
&lt;p&gt;The main configuration of my website can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config"&gt;this repository&lt;/a&gt;
As mentioned before, the website is created with pelican, a static website 
generator written in python. There are a bunch of alternatives on the market 
(Jekyll comes to mind but also newer generators like Hugo), however I picked 
pelican because of its python support, a language I am already quite comfortable
with. As much as I enjoy learning new languages, in this case I wanted something
I could get up and running without struggling too much (of course being me, I 
did struggle with it, but that's besides the point). &lt;/p&gt;
&lt;p&gt;Besides pelican I have used Gulp to compile my own crafted theme, and do a little
bit of optimisation. The examples within this blog post will thus be focused on
these technologies. However, it should be rather trivial to adapt the examples 
to any other static website generator. In this section I will quickly go over 
the project structure,and how the technologies are set up. For further detail 
I would refer you to the documentation of the specific tools, as the focus of
the rest of the article is on how to set up the Azure DevOps pipelines.&lt;/p&gt;
&lt;h2&gt;Folder Structure&lt;/h2&gt;
&lt;p&gt;The static website basically consists of three parts, the theme, which can be
found in &lt;a href="https://github.com/BeardedPlatypus/rubber-squid"&gt;this repository&lt;/a&gt;, 
the content, which can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-content"&gt;this repository&lt;/a&gt;
and lastly the configuration files, which can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config"&gt;this repository&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;After completing a full run of the compilation of the website we will have 
the following (simplified) directory structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;Base                  # config git repository&lt;/span&gt;
&lt;span class="err"&gt;â”œâ”€â”€â”€content           # content git repository&lt;/span&gt;
&lt;span class="err"&gt;â”‚   â”œâ”€â”€â”€articles&lt;/span&gt;
&lt;span class="err"&gt;â”‚   â””â”€â”€â”€pages&lt;/span&gt;
&lt;span class="err"&gt;â”œâ”€â”€â”€plugins           # plugins used by pelican&lt;/span&gt;
&lt;span class="err"&gt;â”œâ”€â”€â”€production        # output folder of pelican&lt;/span&gt;
&lt;span class="err"&gt;â”œâ”€â”€â”€theme&lt;/span&gt;
&lt;span class="err"&gt;â”‚   â””â”€â”€â”€rubber-squid&lt;/span&gt;
&lt;span class="err"&gt;â”‚       â”œâ”€â”€â”€static&lt;/span&gt;
&lt;span class="err"&gt;â”‚       â””â”€â”€â”€templates&lt;/span&gt;
&lt;span class="err"&gt;â””â”€â”€â”€website_dist      # output of gulp postPelican&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, the content folder is checked out as separate repository in the
config folder, and the theme is checked out in the theme folder. I could have 
set this up with the help of git submodules, however I have not done this yet,
and for the current purposes, this set up suffices.&lt;/p&gt;
&lt;h2&gt;Pelican&lt;/h2&gt;
&lt;p&gt;Pelican is configured through the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/pelicanconf.py"&gt;pelican.conf&lt;/a&gt;
and the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/publishconf.py"&gt;publish.conf&lt;/a&gt;.
Within these files things like the theme, names etc are specified. In addition
to the default pelican, I also use the summary plugin, which helps creating the
summaries for the blog index page. I have modified this slightly to remove any
links from within the summaries.&lt;/p&gt;
&lt;p&gt;When pelican is properly installed, the static website can be generated through
the following command: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;pelican content -s publishconf.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will create all the html pages based on your content, theme and 
configuration in the &lt;code&gt;production&lt;/code&gt; folder. The contents of this folder
could be uploaded immediately to a github pages repository, and it 
would be available for viewing. However we can do a little bit better and 
optimise the result of pelican with some javascript magic.&lt;/p&gt;
&lt;h2&gt;Gulp&lt;/h2&gt;
&lt;p&gt;When I created the previous incarnation of this website, I did not know anything
about web optimisation, since then I have learned some new tricks and figured 
I wanted to incorporate them. Building my website now has a pre and post step
besides the pelican compile step.&lt;/p&gt;
&lt;p&gt;Before we can build the website, we first need to compile the theme, or more 
specifically, the sass files, such that we have some css that pelican can use.
As mentioned before, once the compilation is done, we can then further optimise
the output a bit by calling some other javascript magic.&lt;/p&gt;
&lt;p&gt;Both of these steps are managed by &lt;a href="https://gulpjs.com/"&gt;Gulp&lt;/a&gt;.
I set up a simple  workflow, based upon 
&lt;a href="https://css-tricks.com/gulp-for-beginners/"&gt;this tutorial&lt;/a&gt; to do so.&lt;/p&gt;
&lt;p&gt;The pre step at the moment of writing merely compiles the sass files through the
following gulp command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gulp prePelican&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The post pelican step collects all css files, concatenates them, and minimises them,
and puts them in a &lt;code&gt;website_dist&lt;/code&gt; folder. It also copies over any of the html, 
js, and feed files. I currently have not set up the minimisation of the js file, 
as I already did this in a separate step, when I created my own js. However in the
future there is a good chance I will add this. This step can be executed as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gulp postPelican&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The steps themself are set up in the &lt;code&gt;gulp.js&lt;/code&gt; file of the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/gulpfile.js"&gt;config repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that I am nowhere near experienced with any of this, so take this 
set up with a grain of salt, and do your own research in order to find a set up 
that works well for you!&lt;/p&gt;
&lt;h1&gt;Compile the website on Azure DevOps&lt;/h1&gt;
&lt;p&gt;With the extremely short primer out of the way, let's take a look at the actual
build configuration. In essence, we want to do 4 steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compile the theme&lt;/li&gt;
&lt;li&gt;compile pelican&lt;/li&gt;
&lt;li&gt;optimise the pelican output&lt;/li&gt;
&lt;li&gt;push it all to the github pages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in the following section we will take a look at each of these steps, if however
you just want to see the configuration, it can be found 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/azure-pipelines.yml"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the sake of brevity, I am going to assume you already have a project set up, 
and can know where to find the add build pipeline button. If you do not know this,
I recommend going over the documentation of Azure DevOps, it should not take long to
set up.&lt;/p&gt;
&lt;h2&gt;Setting up the Pelican Components&lt;/h2&gt;
&lt;p&gt;In order to set up our pipeline, we need to make use of python and javascript. We will
start with python, and then move on to the nodejs component.&lt;/p&gt;
&lt;p&gt;The main build line should be based in our config repository, as this one will hold all
the information to actually build the website. As such, I selected GitHub as my source 
of my code, and then the config repository. Since we want to use python for our pelican
application build, I started out with the python package configuration as base. &lt;/p&gt;
&lt;p&gt;We only need a single python version, as we only build our website once. Furthermore,
at the time of writing I did not include any python testing, so I removed this step to.
This leaves us with the following yml code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;# Python package&lt;/span&gt;
&lt;span class="cp"&gt;# Create and test a Python package on multiple Python versions.&lt;/span&gt;
&lt;span class="cp"&gt;# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:&lt;/span&gt;
&lt;span class="cp"&gt;# https:&lt;/span&gt;&lt;span class="c1"&gt;//docs.microsoft.com/azure/devops/pipelines/languages/python&lt;/span&gt;

&lt;span class="nl"&gt;trigger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;

&lt;span class="nl"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;vmImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="nl"&gt;strategy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;Python37&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nl"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;3.7&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="nl"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;UsePythonVersion&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Use&lt;/span&gt; &lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;upgrade&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt;
    &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;dependencies&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;First it defines a trigger, this means that whenever a commit is made on the 
branches listed under it, this specific build will trigger. Since we only want
to actually build and push or website when we make a definitive commit, we can
leave this on master.&lt;/p&gt;
&lt;p&gt;Next some strategies are defined. If we had an actual python package to test, 
we might want to do that for different versions. However, we only need one 
version of python, so we can remove all but the 3.7 version, as this is the 
latest.&lt;/p&gt;
&lt;p&gt;In the following step it gets the specific python version, and then 
installs our requirements.txt file. The requirements file specifies which packages
need to be installed. For pelican we need both the pelican package and the markdown
package, as such it looks liks this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;Markdown==3.1.1&lt;/span&gt;
&lt;span class="err"&gt;pelican==4.0.1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once these steps have executed, we have our python installation ready to use, and
we can add the pelican compile step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;- script: |&lt;/span&gt;
&lt;span class="err"&gt;    pelican content -s publishconf.py&lt;/span&gt;
&lt;span class="err"&gt;  displayName: &amp;#39;Pelican Compile&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, it merely executes our pelican command, as we defined it the previous
section. The &lt;code&gt;displayName&lt;/code&gt; will be shown in the summary of Azure DevOps, and makes
debugging a bit easier, so I try to give it a relevant name, but you could always
change or even remove it.&lt;/p&gt;
&lt;p&gt;We can add this part right after the python bit and execute it. Unfortunately. This
code does not work yet, as we do not have our data to act on. Before we set this up
though, let's add the javascript bit to our code.&lt;/p&gt;
&lt;h2&gt;Setting up the nodejs / npm components&lt;/h2&gt;
&lt;p&gt;If we instead had started with Node.js pipeline, our template would have looked like 
this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;# Node.js&lt;/span&gt;
&lt;span class="cp"&gt;# Build a general Node.js project with npm.&lt;/span&gt;
&lt;span class="cp"&gt;# Add steps that analyze code, save build artifacts, deploy, and more:&lt;/span&gt;
&lt;span class="cp"&gt;# https:&lt;/span&gt;&lt;span class="c1"&gt;//docs.microsoft.com/azure/devops/pipelines/languages/javascript&lt;/span&gt;

&lt;span class="nl"&gt;trigger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;

&lt;span class="nl"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;vmImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="nl"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NodeTool&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It uses the same pool and trigger as our python script, and contains the steps to
install Node.js and npm. Therefore we can just copy these install steps to the 
configuration we are setting up.&lt;/p&gt;
&lt;p&gt;We can remove the npm run build step, as we are not building an actual Node.js 
application, we merely want it to install gulp. Once we call the npm
install step, all the packages from our &lt;code&gt;package.json&lt;/code&gt; are installed. For this
website this is basically gulp, and some supporting plugins, see 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/package.json"&gt;here&lt;/a&gt;.
After running the install, we can use gulp to compile our team and optimise the
output of pelican.&lt;/p&gt;
&lt;p&gt;Since we defined all our pre-pelican steps in one command, the step in our configuration
becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;- script: |&lt;/span&gt;
&lt;span class="err"&gt;    gulp prePelican&lt;/span&gt;
&lt;span class="err"&gt;  displayName: &amp;#39;Pre-Pelican Compile&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the post pelican step becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;- script: |&lt;/span&gt;
&lt;span class="err"&gt;    gulp postPelican&lt;/span&gt;
&lt;span class="err"&gt;  displayName: &amp;#39;Post-Pelican Compile&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We put these commands before and after our pelican step:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="nf"&gt;task:&lt;/span&gt; &lt;span class="n"&gt;UsePythonVersion&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Use&lt;/span&gt; &lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;upgrade&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt;
    &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;dependencies&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NodeTool&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;gulp&lt;/span&gt; &lt;span class="n"&gt;prePelican&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Pre&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;pelican&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;publishconf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;gulp&lt;/span&gt; &lt;span class="n"&gt;postPelican&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With that set up, we are basically all ready to execute our compilation process.
Next up, getting the data.&lt;/p&gt;
&lt;h2&gt;Checking out the additional repositories&lt;/h2&gt;
&lt;p&gt;In order to get our data from github, we basically need to clone our content and
theme repositories. Since I was having some troubles with the script task, I opted
to use the powershell task. This task basically gives access to a powershell instance
in your configuration, and allows you to run a variety of commands. &lt;/p&gt;
&lt;p&gt;Since git comes pre-installed, we do not have to worry about it, and can just use
git commands in our powershell task.&lt;/p&gt;
&lt;p&gt;There might be reasons why you want to keep your theme and content into private
repositories, in order to clone these repositories you will need to authenticate
yourself. Ideally, you would use some token based way to authenticate yourself,
however I have not come around to do so in my own pipeline, so instead we can alse  use 
basic authentication for this within github. In order to do so we need to specify 
our URL as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;https:\\&amp;lt;account_name:account_pw@github.com/&amp;lt;repository account name&amp;gt;/&amp;lt;repository name&amp;gt;.git&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We do not want to leak this information in our build logs. Therefore we are going 
to use private variables, 
&lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;amp;tabs=yaml%2Cbatch"&gt;as microsoft recommends&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thus our clone steps then become:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;powershell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;github.com/BeardedPlatypus/rubber-squid.git&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;:$env:GITHUB_PW@$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;https://$url&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;clone&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;theme/rubber-squid&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Check out - Rubber Squid Theme&amp;#39;&lt;/span&gt;
  &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_ACCOUNT&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;profile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_PW&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;powershell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;github.com/BeardedPlatypus/personal-website-content.git&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;:$env:GITHUB_PW@$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;https://$url&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;clone&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;
  &lt;span class="n"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Check out - Blog Content&amp;#39;&lt;/span&gt;
  &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_ACCOUNT&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;profile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_PW&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first steps are done to build our URL as described above. I had 
some trouble getting this to work too be honest, and this ended up
working correctly, so I decided to stick with it.&lt;/p&gt;
&lt;p&gt;Once we have build our URL, we can clone our repositories. Because
pelican expects them in a specific place relative to our working 
directory, we add the folder we want them in.&lt;/p&gt;
&lt;p&gt;I have added these steps before I even install python or Node.js.
The chance that these steps fail as opposed to the install steps
is greater, and we rather fail earlier than later.&lt;/p&gt;
&lt;h2&gt;Getting some artifacts&lt;/h2&gt;
&lt;p&gt;Now that we have all our compilation steps set up, once we run
our build confiration, we should have a nice &lt;code&gt;website_dist&lt;/code&gt; folder,
containing our whole website. Before we push this to our github 
pages, let's add some steps to publish this as an artifact as well.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="nf"&gt;task:&lt;/span&gt; &lt;span class="n"&gt;CopyFiles&lt;/span&gt;&lt;span class="mi"&gt;@2&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;website_dist&lt;/span&gt;&lt;span class="cm"&gt;/**&amp;#39;&lt;/span&gt;
&lt;span class="cm"&gt;    targetFolder: $(Build.ArtifactStagingDirectory)&lt;/span&gt;
&lt;span class="cm"&gt;  displayName: &amp;#39;Artifacts - Copy&amp;#39;&lt;/span&gt;

&lt;span class="cm"&gt;- task: PublishBuildArtifacts@1&lt;/span&gt;
&lt;span class="cm"&gt;  inputs:&lt;/span&gt;
&lt;span class="cm"&gt;    pathToPublish: $(Build.ArtifactStagingDirectory)&lt;/span&gt;
&lt;span class="cm"&gt;    artifactName: websiteContents&lt;/span&gt;
&lt;span class="cm"&gt;  displayName: &amp;#39;Artifacts - Publish&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will output our &lt;code&gt;website_dist&lt;/code&gt; for us to inspect, and ensure
the website was generated correctly. We could further extend this
to also publish the output of pelican, or the first gulp step 
for example. This could help with debugging.&lt;/p&gt;
&lt;h2&gt;Pushing the content to github pages&lt;/h2&gt;
&lt;p&gt;In order to push our content to our github pages repository, we
need to do the following things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clear our repository&lt;/li&gt;
&lt;li&gt;Add the output of our postPelican step&lt;/li&gt;
&lt;li&gt;Commit the changes&lt;/li&gt;
&lt;li&gt;Push the content&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to clear out the content of our current github pages
repository, we can create an empty check out of our repo, in
the &lt;code&gt;website_dist&lt;/code&gt; folder. This can be achieved with the 
following step:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;- powershell: |&lt;/span&gt;
&lt;span class="err"&gt;    git clone --no-checkout &amp;quot;https://github.com/BeardedPlatypus/BeardedPlatypus.github.io&amp;quot; website_dist&lt;/span&gt;
&lt;span class="err"&gt;  displayName: &amp;#39;Check out - BeardedPlatypus.io&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--no-checkout&lt;/code&gt; flag will ensure we do not check out any files.
If we were to commit this as is, it would clear our whole repository.
We want to put this step before our &lt;code&gt;postPelican&lt;/code&gt; step, such that the
folder is still empty (otherwise git will complain).&lt;/p&gt;
&lt;p&gt;Now, once we have passed the &lt;code&gt;postPelican&lt;/code&gt; step, we can actually 
add all the files generated, commit, and push them. The step to
do this looks as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;powershell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;$env:USER_EMAIL&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;$env:USER_NAME&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="k"&gt;commit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;Automated update: $(Build.BuildNumber)&amp;quot;&lt;/span&gt;

    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;github.com/BeardedPlatypus/BeardedPlatypus.github.io.git&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;:$env:GITHUB_PW@$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;&lt;/span&gt;
    &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;https://$url&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;git&lt;/span&gt; &lt;span class="n"&gt;push&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;
  &lt;span class="n"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Update BeardedPlatypus.io&amp;#39;&lt;/span&gt;
  &lt;span class="n"&gt;workingDirectory&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;website_dist&lt;/span&gt;
  &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_ACCOUNT&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;profile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;GITHUB_PW&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;password&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;USER_NAME&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;USER_EMAIL&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will execute this step in the &lt;code&gt;website_dist&lt;/code&gt; folder, as such
the &lt;code&gt;workingDirectory&lt;/code&gt; property of this step is pointing to this
folder. This will make it possible to refer just to the content
of this folder, and use the &lt;code&gt;--no-checkout&lt;/code&gt; local repository we 
just cloned.&lt;/p&gt;
&lt;p&gt;We start by setting up our &lt;code&gt;user.email&lt;/code&gt; and &lt;code&gt;user.name&lt;/code&gt; in order to be 
able to push our content to the repository in the final step. 
Next, we add and commit all the changes currently existing in the 
folder. Because the empty folder should already have been staged due
to the &lt;code&gt;--no-checkout&lt;/code&gt; flag, this should leave us with the files as 
they are in &lt;code&gt;website_dist&lt;/code&gt;. Furthermore, if there are no changes, 
git will just say everything is up to date, and finish up everything. &lt;/p&gt;
&lt;p&gt;After this, we again build our url, and push to the master branch of
the github pages repository. And with that we have our automatic 
deployment of our static website. &lt;/p&gt;
&lt;p&gt;The full &lt;code&gt;azure-pipelines.yml&lt;/code&gt; can be found 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/azure-pipelines.yml"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Triggering the build on content and theme changes&lt;/h2&gt;
&lt;p&gt;Unfortunately, we currently only trigger the build automatically when
we make a change to the configuration repository. Ideally, this repository
would change little, and most of the changes would be either to
the content or the theme. Thus, whenever we make a change to either 
of these repositories, we would need to do a manual run, which really
is not that much better than doing it by hand on your local machine.&lt;/p&gt;
&lt;p&gt;We can do better! As far as I know, we cannot directly add triggers
that go off once we make changes to these repositories, as one build
only works with one base repository. However, we can make our current
build trigger upon the completion of other builds. Therefor, we will
add some really simple build pipelines for these two repositories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;trigger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;

&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;vmImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ubuntu-latest&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;echo&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;Theme has been triggered.&amp;quot;&lt;/span&gt;
  &lt;span class="n"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Theme&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You could in theory extend these with some sanity or sanitary checks,
such that you do not kick off builds if you know something is wrong,
for now however I have set them up to merely do a simple echo and 
wrap up.&lt;/p&gt;
&lt;p&gt;Once we have set up these pipelines, you can add the completion of
these pipelines as triggers under the trigger settings of our
main build pipeline. Once that is done, our main build should 
trigger automatically. You can try it by running our newly added
pipeline once, and then check if our main gets triggered subsequently.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this article, we set up a simple Azure DevOps build to compile a static
website. We have gone over how to set up the python task to execute pelican,
and how to further optimise the results with the help of gulp. Finally, we
have set it up in such a way that changes to either the theme or content
repositories will ensure the website gets automatically updated and pushed
to the github pages repository.&lt;/p&gt;
&lt;p&gt;We could further extend this pipeline by adding additional optimisation. 
Furthermore, the build pipelines of both the theme and content could be
extended with additional checks, to ensure we only push when we can create
a valid website. For the time being though I am quite happy with the result.&lt;/p&gt;
&lt;p&gt;Thanks for reading, and I hope to see you soon again in another article!&lt;/p&gt;</content></entry><entry><title>Creating a sticky header with elm(-ish)</title><link href="beardedplatypus.github.io/creating-a-sticky-header-with-elm-ish.html" rel="alternate"></link><published>2018-03-08T00:00:00+01:00</published><updated>2018-03-08T00:00:00+01:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2018-03-08:beardedplatypus.github.io/creating-a-sticky-header-with-elm-ish.html</id><summary type="html">&lt;p&gt;I have added a simple sticky header to this blog (at the time of writing). I 
figured I would write a little article about the design and code, both as a 
personal reminder and to hopefully help people like you. This sticky header is
written in elm(-ish). For those â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have added a simple sticky header to this blog (at the time of writing). I 
figured I would write a little article about the design and code, both as a 
personal reminder and to hopefully help people like you. This sticky header is
written in elm(-ish). For those that do not know &lt;a href="http://elm-lang.org"&gt;elm&lt;/a&gt;, it
is basically a functional programming languages which compiles into Javascript.
It allows one to build interactive web applications without run-time errors.
Ever since I had to use it for an university project, I have loved this little
language.&lt;/p&gt;
&lt;p&gt;Using elm for such a small element of my blog is probably overkill, and a couple
of lines of simple Javascript could have sufficed as well. However, me being me, 
I opted for the more convoluted approach. The main reason to use elm, is to 
explore how well it would play together with 
&lt;a href="https://blog.getpelican.com"&gt;Pelican&lt;/a&gt;, the static site generator I use for this
blog. Furthermore, since it is such a small feature of the site, it was a good 
simple exercise to keep my elm skills a bit fresh. So without further ado, let's
take a look at the header.&lt;/p&gt;
&lt;h1&gt;Layout&lt;/h1&gt;
&lt;p&gt;The header I had envisioned is quite simple. The top part would be contain 
some branding in the form of "Monthy's Blog" in big letters. Underneath that
the navbar containing links to the blog, about-me and portfolio pages.
The navbar should turn sticky once we scrolled past the branding. &lt;/p&gt;
&lt;p&gt;This leads to the following layout hierarchy: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;div: banner&lt;ul&gt;
&lt;li&gt;div: navbar&lt;ul&gt;
&lt;li&gt;div: brand&lt;/li&gt;
&lt;li&gt;div: navigation elements&lt;ul&gt;
&lt;li&gt;link: blog&lt;/li&gt;
&lt;li&gt;link: about me&lt;/li&gt;
&lt;li&gt;link: portfolio&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;with the layout planned, we can move to implementing the header in elm.&lt;/p&gt;
&lt;h1&gt;Code and Pelican Interop&lt;/h1&gt;
&lt;p&gt;We divide the code into two parts, first I'll go over all the elm code needed
to get the header working. Then we will look at the html/javascript side.&lt;/p&gt;
&lt;h2&gt;Elm&lt;/h2&gt;
&lt;p&gt;Web apps, no matter the size, generally use the same typical architecture.
This architecture is explained in depth in the main elm tutorial, which can be
found &lt;a href="https://guide.elm-lang.org/architecture/"&gt;here&lt;/a&gt;. The basic structure 
consists of three components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model: holds the state of the application&lt;/li&gt;
&lt;li&gt;Msg / Update: provides the method of updating your Model based upon messages
                that the app can send.&lt;/li&gt;
&lt;li&gt;View: describes how the model is displayed and how messages are generated 
        based upon user-input.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Model&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;type&lt;/span&gt; &lt;span class="kr"&gt;alias&lt;/span&gt; &lt;span class="kt"&gt;NavElement&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kr"&gt;type&lt;/span&gt; &lt;span class="kr"&gt;alias&lt;/span&gt; &lt;span class="kt"&gt;Model&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;List&lt;/span&gt; &lt;span class="kt"&gt;NavElement&lt;/span&gt;
                   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;title&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
                   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;is_fixed&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Bool&lt;/span&gt;
                   &lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;List&lt;/span&gt; &lt;span class="kt"&gt;NavElement&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Model&lt;/span&gt;
&lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="nv"&gt;title&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt;
                                  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;title&lt;/span&gt;        &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;title&lt;/span&gt;
                                  &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;is_fixed&lt;/span&gt;     &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;False&lt;/span&gt;
                                  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The model consists of three elements. &lt;code&gt;nav_elements&lt;/code&gt; describes the navigation
elements, these consist of a name of the page, i.e. blog, and the url to the
specific website page. The &lt;code&gt;title&lt;/code&gt; describes the title which is placed in the 
branding section of the header. Finally, &lt;code&gt;is_fixed&lt;/code&gt; describes whether the 
navigational elements should be fixed or not. &lt;/p&gt;
&lt;h3&gt;Update / Msg&lt;/h3&gt;
&lt;p&gt;The only change that can currently happen within the header, is the switch 
from non-fixed navigational elements to fixed navigational elements, and 
vice-versa. This is modelled in the &lt;code&gt;is_fixed&lt;/code&gt; element of the Model, and 
updated in the &lt;code&gt;update&lt;/code&gt; function. The amount scrolled by the user can be
modelled as a float value. Each time the user scrolls up or down, the app
receives a new float value describing the new situation. As such we need
to define a single message containing this new float:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;type&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;UpdateScrollPos&lt;/span&gt; &lt;span class="kt"&gt;Float&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Whenever the user scrolls, this value is passed to the update which function
which determines if the &lt;code&gt;is_fixed&lt;/code&gt; attribute should be updated.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;update&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Model&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;Cmd&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;update&lt;/span&gt; &lt;span class="nv"&gt;msg&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt;
  &lt;span class="kr"&gt;case&lt;/span&gt; &lt;span class="nv"&gt;msg&lt;/span&gt; &lt;span class="kr"&gt;of&lt;/span&gt;
    &lt;span class="kt"&gt;UpdateScrollPos&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nf"&gt;|&lt;/span&gt; &lt;span class="nv"&gt;is_fixed&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;x&lt;/span&gt; &lt;span class="nf"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mf"&gt;81.&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
      &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;Cmd&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;none&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We set &lt;code&gt;is_fixed&lt;/code&gt; to true, whenever we scroll past 81.3, and to false, when this
is not the case. The value 81.3 is equal to the size of the branding. Of course
it would be significantly more elegant if we could determine this value in code,
instead of hard coding it. However, I have not found this option in elm at the 
current moment. Thus, this has to suffice for now.&lt;/p&gt;
&lt;h3&gt;View&lt;/h3&gt;
&lt;p&gt;Now that we have defined the model, and how to update, it is time to implement 
the determined layout in elm: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;viewNavElement&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;NavElement&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Html&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;
&lt;span class="nv"&gt;viewNavElement&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;txt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt;
  &lt;span class="nv"&gt;li&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
     &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;a&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;href&lt;/span&gt; &lt;span class="nv"&gt;url&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
         &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="nv"&gt;txt&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
     &lt;span class="p"&gt;]&lt;/span&gt;


&lt;span class="nv"&gt;viewNavElements&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;List&lt;/span&gt; &lt;span class="kt"&gt;NavElement&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Bool&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Html&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;
&lt;span class="nv"&gt;viewNavElements&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="nv"&gt;is_fixed&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt;
  &lt;span class="kr"&gt;let&lt;/span&gt;
    &lt;span class="nv"&gt;att&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;nav&amp;quot;&lt;/span&gt;
          &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;navbar-nav&amp;quot;&lt;/span&gt;
          &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;banner-background&amp;quot;&lt;/span&gt;
          &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;banner-background-bottom&amp;quot;&lt;/span&gt;
          &lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="kr"&gt;in&lt;/span&gt;
    &lt;span class="nv"&gt;ul&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;is_fixed&lt;/span&gt; &lt;span class="kr"&gt;then&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;sticky&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nf"&gt;::&lt;/span&gt; &lt;span class="nv"&gt;att&lt;/span&gt; &lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="nv"&gt;att&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
       &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kt"&gt;List&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;map&lt;/span&gt; &lt;span class="nv"&gt;viewNavElement&lt;/span&gt; &lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nv"&gt;view&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Model&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Html&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;
&lt;span class="nv"&gt;view&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt;
  &lt;span class="kr"&gt;let&lt;/span&gt;
    &lt;span class="nv"&gt;brand&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;div&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;is_fixed&lt;/span&gt; &lt;span class="kr"&gt;then&lt;/span&gt;
                    &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;navbar-brand&amp;quot;&lt;/span&gt;
                    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;banner-background&amp;quot;&lt;/span&gt;
                    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;fixed-padding&amp;quot;&lt;/span&gt;
                    &lt;span class="p"&gt;]&lt;/span&gt;
                  &lt;span class="kr"&gt;else&lt;/span&gt;
                    &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;navbar-brand&amp;quot;&lt;/span&gt;
                    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;banner-background&amp;quot;&lt;/span&gt;
                    &lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;title&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nv"&gt;navbar&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;viewNavElements&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;nav_elements&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;is_fixed&lt;/span&gt;

  &lt;span class="kr"&gt;in&lt;/span&gt;
    &lt;span class="nv"&gt;div&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;id&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;banner&amp;quot;&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;nav&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;id&lt;/span&gt;    &lt;span class="s"&gt;&amp;quot;site-navigation&amp;quot;&lt;/span&gt;
              &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;navbar&amp;quot;&lt;/span&gt;
              &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;attribute&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;role&amp;quot;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;navigation&amp;quot;&lt;/span&gt;
              &lt;span class="p"&gt;]&lt;/span&gt;
              &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="nv"&gt;brand&lt;/span&gt;
              &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;navbar&lt;/span&gt;
              &lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This function describes both the fixed and non-fixed situations, by adding
additional classes to the elements when the header should be fixed. If the 
header is fixed, then the brand should extend to the size of the navigational
elements as well. This way, the content does not jump upward, due to the height
of the navigational elements being removed from the header. This is done by
adding the &lt;code&gt;fixed_padding&lt;/code&gt; class to the brand. The bar containing the nav
elements is made sticky by adding the &lt;code&gt;sticky class&lt;/code&gt; to the &lt;code&gt;ul&lt;/code&gt; class.
The layout of the elements is equal to the layout described earlier.&lt;/p&gt;
&lt;h2&gt;Html / Javascript&lt;/h2&gt;
&lt;p&gt;In order to get the header to fully work, two more problems need to be dealt 
with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialisation of the pages and title.&lt;/li&gt;
&lt;li&gt;Updates of the scroll position.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Initialisation of the elm app&lt;/h3&gt;
&lt;p&gt;In theory, we could hard code the names and pages in the elm code. However,
this would mean, each time we want to make a small change to the name of the
site, or add / remove pages from the navbar, we would need to edit the elm code
again. Hardly a preferable situation. It would be a lot nicer if this data is 
set in the html code which is generated by Pelican. Fortunate for us, this is 
possible by using a mechanism called &lt;a href="https://guide.elm-lang.org/interop/javascript.html"&gt;flags&lt;/a&gt;.
Basically, we define a set of values to be used in elm, which are provided in
the html file in which the elm app is embedded:&lt;/p&gt;
&lt;p&gt;First we define a &lt;code&gt;Flags&lt;/code&gt; record, describing the elements which will be passed
to the elm app:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;type&lt;/span&gt; &lt;span class="kr"&gt;alias&lt;/span&gt; &lt;span class="kt"&gt;Flags&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nv"&gt;brand&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;
                   &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;pages&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;List&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                   &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then we use these flags to create an init function, which will be used by the
&lt;code&gt;Html.programWithFlags&lt;/code&gt; to create our app:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;init&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Flags&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;Cmd&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;init&lt;/span&gt; &lt;span class="nv"&gt;flags&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;pages&lt;/span&gt; &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;brand&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;Cmd&lt;/span&gt;&lt;span class="nf"&gt;.&lt;/span&gt;&lt;span class="nv"&gt;none&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then finally we can add the appropriate values in the html code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;node&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;header&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;Elm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Header&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;node&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;brand&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Monthy&amp;#39;s Blog&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nx"&gt;pages&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Blog&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{{ SITEURL  }}/index.html&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
           &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nx"&gt;p&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="nx"&gt;pages&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
           &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{ p.title }}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{{ SITEURL }}/{{ p.url }}&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
           &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nx"&gt;endfor&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
           &lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we see how pelican and elm can play nicely together. The elm app receives
the Flags field as a dictionary parameter. The flags entries contain the values
as they are defined in the elm file, in our case this is brand and pages. 
The pages value is set as a pelican template command, which upon generation will
add all the pages as values in our final generated html code. Success!&lt;/p&gt;
&lt;h3&gt;Scroll Updates&lt;/h3&gt;
&lt;p&gt;Earlier, we mentioned that we receive scroll updates in the form of floats, 
however, I did not specify where these updates came from. Unfortunately, I 
haven't found a way to subscribe to scroll updates directly in elm, so we 
will have to parse them from javascript. This is possible through the use
of ports, which allows javascript to communicate with our elm app. &lt;/p&gt;
&lt;p&gt;In order to use ports we need to define our module as a ports module by adding
the ports keyword in front of module.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;port&lt;/span&gt; &lt;span class="kr"&gt;module&lt;/span&gt; &lt;span class="kt"&gt;Header&lt;/span&gt; &lt;span class="nv"&gt;exposing&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="nf"&gt;..&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Afterwards we can define our port that will receive the javascript updates:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;port&lt;/span&gt; &lt;span class="nv"&gt;onScroll&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;Float&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nv"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Sub&lt;/span&gt; &lt;span class="nv"&gt;msg&lt;/span&gt;

&lt;span class="nv"&gt;subscriptions&lt;/span&gt; &lt;span class="nf"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Model&lt;/span&gt; &lt;span class="nf"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kt"&gt;Sub&lt;/span&gt; &lt;span class="kt"&gt;Msg&lt;/span&gt;
&lt;span class="nv"&gt;subscriptions&lt;/span&gt; &lt;span class="nv"&gt;model&lt;/span&gt; &lt;span class="nf"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;onScroll&lt;/span&gt; &lt;span class="kt"&gt;UpdateScrollPos&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This port is combined in the subscriptions used by our application. Every time
we receive a float on this port, it is turned into an &lt;code&gt;UpdateScrollPos&lt;/code&gt; message,
which will be run through our &lt;code&gt;update&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Now that we have defined how to deal with updates on the elm side, let's 
generate them at the javascript side:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  &lt;span class="nb"&gt;window&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;onscroll&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;updateScroll&lt;/span&gt;&lt;span class="p"&gt;()};&lt;/span&gt;

  &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;updateScroll&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;app&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ports&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;onScroll&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;window&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;pageYOffset&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We register a callback on &lt;code&gt;window.onscroll&lt;/code&gt;. This means that whenever the user
scrolls, our callback is executed. In our case, this executes the 
&lt;code&gt;updateScroll()&lt;/code&gt; function, which sends the &lt;code&gt;window.pageYOffset&lt;/code&gt; to our header.
And with that, we now generate updates whenever the user scrolls on the blog,
allowing elm to determine whether the header should be sticky or not.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this article I have described how I implemented a simple sticky header in 
elm. Overall I would argue that this approach is probably overkill, and a simple
javascript approach would be both simpler and more performant At the same time,
I have shown that elm can work quite nicely with Pelican, thus proving it feasible
to build apps combining both technologies. With that in mind I am happy with the 
results and will continue using this header for the time being! &lt;/p&gt;
&lt;p&gt;There are two aspects, I will most likely work a bit more on. Firstly, I am not
quite satisfied with the transition of non-sticky to sticky, which seems to be 
primarily caused by the size of the brand padding in the sticky situation. I 
will probably tweak the margin / padding a bit more, to ensure it feels smooth.
Secondly, I would like to add a simple gif/animation to the header. This would 
mean I would need to expand my elm code a little bit to make this possible. 
As such, future versions of the header might look a bit differently than the 
one described here. &lt;/p&gt;
&lt;p&gt;The full code for these examples can be found in 
&lt;a href="https://gist.github.com/BeardedPlatypus/f33e41a5af8007a947bbcccef50eea1b"&gt;this gist&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks for reading, and hopefully see you again!&lt;/p&gt;</content><category term="elm"></category><category term="html"></category></entry><entry><title>Setting up a markdown/LaTeX document.</title><link href="beardedplatypus.github.io/setting-up-a-markdownlatex-document.html" rel="alternate"></link><published>2017-10-05T00:00:00+02:00</published><updated>2017-10-05T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2017-10-05:beardedplatypus.github.io/setting-up-a-markdownlatex-document.html</id><summary type="html">&lt;p&gt;In this article we'll take a quick look on how to set up a markdown / LaTeX 
project with the help of Python and Pandoc. The goal is to have a single command
to compile a set of markdown documents into a single LaTeX pdf. As an example 
project I've modified â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this article we'll take a quick look on how to set up a markdown / LaTeX 
project with the help of Python and Pandoc. The goal is to have a single command
to compile a set of markdown documents into a single LaTeX pdf. As an example 
project I've modified my master thesis paper to consist of markdown files. &lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;LaTeX is a great tool to write beautiful looking documents, however it can be a 
bit ehm... cumbersome, especially the syntax. Markdown on the other hand is a 
wonderfully lightweight markup language that makes writing a joy, at least in my
opinion. Since I had to write a master thesis, I figured I would try and get the
best of both worlds and write my content in markdown, which I would then 
transform into LaTeX documents, which I could compile normally. For those that 
don't know me, I must admit I'm a sucker for convoluted solutions to problems, 
and I can't deny that this played a role into settling on this approach.&lt;/p&gt;
&lt;p&gt;I'm far from the first to explore this approach, there are several blogposts on
the web that, ..., and I have drawn inspiration from those. &lt;/p&gt;
&lt;h1&gt;Tools&lt;/h1&gt;
&lt;p&gt;The main tool, which most blogposts use, is Pandoc. Pandoc is a tool that can
transform text files from a wide variety of syntaxes into different syntaxes. 
On top of that it is free software released under the GPL. The scrooge in me 
can definitely appreciate that. &lt;/p&gt;
&lt;p&gt;After we have transformed the files from markdown to latex, they need to be 
compiled to a pdf, I personally use &lt;code&gt;pdflatex&lt;/code&gt; for that, mostly due to the
fact I'm lazy and haven't looked into other options like XeLaTeX or LuaTeX.
We won't venture too much into the domain of LaTeX itself. I'll assume you
already are familiar with it, if not I definitely recommend taking a look at it.
It is definitely my go to tool for creating documents.&lt;/p&gt;
&lt;p&gt;Lastly we'll use Python to wrap all the different terminal commands into a
single build command. This script will copy the relevant files from the source
folder into a build folder, and then call the appropriate compile functions.
For this we make use of several libraries. All the paths will be done with the
&lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;pathlib library&lt;/a&gt; which comes 
bundled with Python 3. In order to make it possible to run the build function
as a commandline task instead of a script we use &lt;a href="http://www.pyinvoke.org"&gt;Invoke&lt;/a&gt;.
Finally we use &lt;a href="https://plumbum.readthedocs.io/en/latest/"&gt;plumbum&lt;/a&gt; to access
the different executables we need to execute.&lt;/p&gt;
&lt;h1&gt;Document structure&lt;/h1&gt;
&lt;p&gt;Before we dive in to setting up the whole project, lets first take a look at the
document structure. In the case of my paper we can discern three parts: an
abstract, a bunch of section making up the main matter, and the appendix. 
Pandoc makes use of templates to convert files from one type to another. In this
case we will define three templates, an abstract, section and appendix template.
These will generate corresponding LaTeX documents. These LaTeX documents will be
included in a single &lt;code&gt;tex&lt;/code&gt; document which will also specify the document class
and LaTeX packages used. This is done with the &lt;code&gt;\input{&amp;lt;path&amp;gt;}&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Each of the images used will be written in LaTeX. Images in LaTeX can
be a finicky business. It would most likely be possible to do this neatly in 
markdown as well. However due to my experience with LaTeX, I figured I should
not try and attempt to do these in markdown. Since Pandoc will automatically 
recognise LaTeX commands in markdown, we can freely mix and match LaTeX and
markdown syntax. Each of the images can thus be efficiently included in a 
markdown document with the &lt;code&gt;\input{&amp;lt;path&amp;gt;}&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;The references used in the paper will also be done with regular LaTeX commands.
The bibliography file used is a single bibtex file. Within the markdown document
the &lt;code&gt;\cite{&amp;lt;label&amp;gt;}&lt;/code&gt; will be used to cite a source.&lt;/p&gt;
&lt;p&gt;In case of the paper, &lt;a href=""&gt;paper.tex&lt;/a&gt; specifies the LaTeX source file, and 
&lt;a href=""&gt;paper.bib&lt;/a&gt; specifies the bibtex file.&lt;/p&gt;
&lt;h1&gt;Setting up the project&lt;/h1&gt;
&lt;p&gt;With the tools, motivation, and document structure out of the way it's time to
get our hands dirty. I will describe the set up as used within my paper project
however keep in mind that in no need you need to abide by this set up, and the 
code and folder structure could be easily adjusted to fit your personal needs.
We will divide the project into three folders, a &lt;code&gt;src&lt;/code&gt; source
folder, which will contain all the files we write ourselves. a &lt;code&gt;build&lt;/code&gt; folder 
generated by the script we will implement in the next section, and a &lt;code&gt;target&lt;/code&gt;
folder which will also be generated by the script. The compile commands of latex
and markdown will be run on the build folder. The final outputted pdf will be 
copied to the target folder. Under normal circumstances we won't need to dig 
around in the build folder.&lt;/p&gt;
&lt;p&gt;The source folder will contain all of our documents. In the top level we will
have three files: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;tex&lt;/code&gt; document specifying our LaTeX document,&lt;/li&gt;
&lt;li&gt;The bibtex document containing our bibliography&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;conf.json&lt;/code&gt; specifying how our document is structured.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore we define three folders:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;content&lt;/code&gt;, which contains all of our markdown files&lt;/li&gt;
&lt;li&gt;&lt;code&gt;img&lt;/code&gt;, which will contain all files pertaining to our images&lt;/li&gt;
&lt;li&gt;&lt;code&gt;layout&lt;/code&gt;, which will contain all the relevant pandoc templates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;content and the conf.json file&lt;/h2&gt;
&lt;p&gt;The content in the paper our structured in a certain way. This structure needs
to be explicitly defined. There are several ways for doing this, I personally
prefer to save this data outside of my documents and use a &lt;a href=""&gt;conf.json file&lt;/a&gt; to
indicate the structure of my document, however alternatives are possible. You
could for example add additional metadata within the filenames and directory names
of the content, and then use some sort of discovery algorithm. That being said, 
it would add additional complexity, which can be circumvented by just using a 
json file to capture the metadata. &lt;/p&gt;
&lt;p&gt;So what's in the json file? Since the json file will be read by the script to
determine the structure of the document will be, basically it contains all
metadata. The top level structure contains the following entries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;main_tex_file&lt;/code&gt; : Specifies the main LaTeX file, which will be compiled with pdflatex.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;main_bib_file&lt;/code&gt; : Specifies the main bibtex file, which will be compiled with bibtex.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;units&lt;/code&gt; : Specifies the structure of the document.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;units&lt;/code&gt; is a list describing each section within the paper. Personally I like 
to subdivide longer files into smaller self-contained elements. In this case, 
I have divided up my sections into subsections. Each subsection gets its own
markdown file. Thus each unit is structure describing a section of the paper.
Each section gets its own folder within content. The folder name is specified
with the &lt;code&gt;folder&lt;/code&gt; entry. The &lt;code&gt;title&lt;/code&gt; describes the title of the section which
will be used in the template. Finally the subunits describe the subsections
of my paper, in the order they appear in. These are separate markdown files,
which will each be read by the script. These subunits will be combined
during the execution of the script to create a single markdown file per section.&lt;/p&gt;
&lt;p&gt;Finally an &lt;code&gt;abstract.md&lt;/code&gt; and &lt;code&gt;appendix.md&lt;/code&gt; are placed within the content 
folder which will be transformed in there respective LaTeX files.&lt;/p&gt;
&lt;p&gt;The content and conf.json file are closely linked. The conf.json file 
basically describes the structure of the content.&lt;/p&gt;
&lt;h2&gt;layout&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;layout&lt;/code&gt; folder contains the Pandoc templates. 
&lt;a href="http://pandoc.org/MANUAL.html#templates"&gt;A Pandoc template&lt;/a&gt; describes how
the content of a file is translated into the different file. In our case
we need three templates&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;section&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""&gt;appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each of these the template is linked. They are rather small files, which
specify where the body is placed. In the case of the section template, an 
additional parameter is added, the title variable. Here the title of the
section will be placed.&lt;/p&gt;
&lt;h2&gt;img&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;img&lt;/code&gt; folder contains all the files related to the images of the project. 
It contains two subfolders, a &lt;code&gt;tex&lt;/code&gt; folder which contains all the &lt;code&gt;tex&lt;/code&gt; files
typesetting the images which are imported in the markdown/LaTeX files, and 
a &lt;code&gt;raw&lt;/code&gt; folder which contains the actual &lt;code&gt;jpeg&lt;/code&gt;, &lt;code&gt;png&lt;/code&gt;, etc. images. &lt;/p&gt;
&lt;p&gt;This is the basic document structure needed to create markdown/LaTeX pdf files.
Next up, the build script that will do all the heavy lifting!&lt;/p&gt;
&lt;h1&gt;The automatisation script&lt;/h1&gt;
&lt;p&gt;In order to convert the &lt;code&gt;src&lt;/code&gt; folder into a compiled pdf, a bunch of steps need
to be taken. First the separate subunit files need to be combined to make the 
section documents. Then these section documents, the abstract and the appendix
need to be copied to the build folder and converted to &lt;code&gt;tex&lt;/code&gt; documents with pandoc. 
All the image files, the main &lt;code&gt;tex&lt;/code&gt; file and the bibliography files also need 
to be copied to the build file. Then in order to get a nicely formatted pdf, 
first pdflatex needs to be run on the main tex file, then bibtex needs to be run, 
and then pdflatex needs to be run twice more (this has something to due with setting
the citations and references within the text properly, though I don't know the exact
details), only then we can copy the generated pdf to the target folder.&lt;/p&gt;
&lt;p&gt;This, of course, is not something you'd want to have to do each time a small change
is made to the document. So we automate it! For each of these steps we will 
write a small function that automates that exact step. Then all these functions
are called in a single invoke task, which we can call by calling &lt;code&gt;invoke build&lt;/code&gt;
in the root folder of our project.&lt;/p&gt;
&lt;p&gt;We start out with a &lt;a href=""&gt;tasks.py&lt;/a&gt; file. This file has to be called &lt;code&gt;tasks.py&lt;/code&gt; such
that invoke recognises it as a file containing invoke commands. I won't go into
too much depth as much of the script should be rather self-explanatory.&lt;/p&gt;
&lt;h2&gt;Supporting functionality&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;local&lt;/code&gt; is a construct defined in &lt;code&gt;plumbum&lt;/code&gt;. It basically allows us to obtain an
executable which can be found on the &lt;code&gt;path&lt;/code&gt; variable of our terminal, and call 
it, like it is a python function. Pretty sweet stuff. In order for this script
to work, it does require &lt;code&gt;pandoc&lt;/code&gt;, &lt;code&gt;pdflatex&lt;/code&gt;, and &lt;code&gt;bibtex&lt;/code&gt; to be on the path
variable. You can test this easily by calling each of these functions within
the terminal. If it throws an error that the command is not recognises, you
either haven't installed it, or you need to add its directory to the path
variable.&lt;/p&gt;
&lt;p&gt;Pandoc requires a couple of flags, in order to know how the files should be
converted. I wrapped these in three functions, to improve the readability.&lt;/p&gt;
&lt;p&gt;Finally we have three helper functions which are responsible for copying files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;update_file&lt;/code&gt;: copies the file at the &lt;code&gt;src&lt;/code&gt; to &lt;code&gt;target&lt;/code&gt; if no file at &lt;code&gt;target&lt;/code&gt;
    exists or it is not equal to &lt;code&gt;src&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_dir&lt;/code&gt;: copies all the files corresponding with the delimiter or set of 
    delimiters, from the &lt;code&gt;src&lt;/code&gt; folder to the &lt;code&gt;target&lt;/code&gt; folder.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;is_str_equal_to_file&lt;/code&gt;: compares the contents of the file and the string on 
    equality. If no file exists it is not equal.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Compile functions&lt;/h2&gt;
&lt;p&gt;Each of the compile functions executes one of the steps defined in the beginning
of this section.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;build_markdown_files&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_main_tex&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_main_bib&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_templates&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_img&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compile_markdown&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compile_latex&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;copy_output&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The update functions merely copy either the specified file or directories, and 
the &lt;code&gt;copy_output&lt;/code&gt; file copies the created pdf to the target.
The more interesting functions are the compile and build functions.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;build_markdown_files&lt;/code&gt; copies the abstract and appendix markdown files 
and then for each section construction a string containing the content of 
that section by appending all the subunits specified in the conf.json file.
In case these have changed since last compilation, they are copied to the
build directory.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;compile_markdown&lt;/code&gt; then compiles each of the markdown files in the &lt;code&gt;md&lt;/code&gt;
subfolder of &lt;code&gt;build&lt;/code&gt;. For this it uses the section template for the sections
and the appendix and abstract for the appendix and abstract files. The output
is saved in &lt;code&gt;build/content&lt;/code&gt;. At the end of the compilation, we have all the 
LaTeX files needed to construct the pdf.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;compile_latex&lt;/code&gt; function calls the 3 pdflatex functions and the bibtex
function in the right order to construct the actual pdf. 
The actual code might is rather straightforward, it specifies the appropriate 
paths and then just calls the executable.&lt;/p&gt;
&lt;h2&gt;Task&lt;/h2&gt;
&lt;p&gt;The last thing left to do is to wrap all of the previous functions into a single
task. This function is called build, and is wrapped inside a &lt;code&gt;@task&lt;/code&gt; decorator.
This will allow invoke to recognise it as a commandline function, which can
then be called with &lt;code&gt;invoke build&lt;/code&gt;. This function reads the configuration file
and then calls all of the previously defined functions. And with that, we can
compile the whole document with just a single command. Whoop whoop.&lt;/p&gt;
&lt;h1&gt;Conclusion and Future work&lt;/h1&gt;
&lt;p&gt;With all of that done, we have shown how to set up a markdown / LaTeX document, which
can be compiled with a single command task. It is a rather straightforward process, 
and can be easily adapted to fit other documents, and it leads to a rather painless
compilation process. &lt;/p&gt;
&lt;p&gt;There are a lot more customisation options which could be included in the script. The
configuration file could be extended with additional elements, like whether elements
should be compiled as sections or chapters. The images should probably be done with
markdown as well. Furthermore the external pandoc executable
should probably be replaced with the appropriate pandoc bindings for the library. 
With each future project involving markdown and LaTeX, I will add a little bit of this 
functionality&lt;/p&gt;
&lt;p&gt;That's it for now, I hope to see you again at the next article!&lt;/p&gt;</content><category term="LaTeX"></category><category term="markdown"></category><category term="python"></category></entry></feed>