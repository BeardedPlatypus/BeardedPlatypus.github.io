<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Monty's Blog - articles</title><link href="beardedplatypus.github.io/" rel="alternate"></link><link href="beardedplatypus.github.io/feeds/articles.atom.xml" rel="self"></link><id>beardedplatypus.github.io/</id><updated>2021-04-03T00:00:00+02:00</updated><entry><title>Learning Unity: Rendering a simple 2D grid with the geometry shader.</title><link href="beardedplatypus.github.io/learning-unity-rendering-a-simple-2d-grid-with-the-geometry-shader.html" rel="alternate"></link><published>2021-04-03T00:00:00+02:00</published><updated>2021-04-03T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2021-04-03:beardedplatypus.github.io/learning-unity-rendering-a-simple-2d-grid-with-the-geometry-shader.html</id><summary type="html">&lt;p&gt;Within this post, we will take a look at geometry shaders within Unity, in
particular how to utilise it to render simple 2D grids in a 3D scene.&lt;/p&gt;
&lt;p&gt;Over the past few weeks I have slowly been getting my feet wet again with 
Unity. I submitted an entry into the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Within this post, we will take a look at geometry shaders within Unity, in
particular how to utilise it to render simple 2D grids in a 3D scene.&lt;/p&gt;
&lt;p&gt;Over the past few weeks I have slowly been getting my feet wet again with 
Unity. I submitted an entry into the &lt;a href="https://ideas.lego.com/challenges/6811cf30-f944-4dfa-8714-9b38be6fbb52?query=&amp;amp;sort=top"&gt;Lego Ideas x Unity&lt;/a&gt; 
competition, which forced me to learn basics. And over the past few weeks I
have been looking at generating 3D worlds from geographical data. 
One of the challenges I set for myself is to render a simple 2D grid in a 3D 
scene. I figured this would be a simple introduction into writing my own 
shaders and explore geometry shaders for a first time. This blog post is
short write-up of the results, and how they were achieved.&lt;/p&gt;
&lt;p&gt;As I am a firm believer in showing the results first and then expanding upon
how it was achieved, this is the final result:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/final.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;As you can see we have a simple 2D grid consisting of lines and points. The
size of these lines and points can be adjusted through the shader. The 
geometry is generated on the fly with a simple C# script. Building this
scene consists of three steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating a new scene with a simple rotating camera.&lt;/li&gt;
&lt;li&gt;Rendering the lines of the grid from line geometry.&lt;/li&gt;
&lt;li&gt;Rendering the points of the grid from point geometry.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following sections will drill down further on these topics. Do note that
I am a complete beginner when it comes to Unity, and as such, anything written
here might not be the ideal solution to the problem, always be critical!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Most of the information of this post has been obtained from &lt;a href="https://jayjingyuliu.wordpress.com/2018/01/24/unity3d-intro-to-geometry-shader/"&gt;this tutorial&lt;/a&gt;, do check it out!&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Set up an empty scene with a simple rotating camera.&lt;/h2&gt;
&lt;p&gt;In order to build anything within Unity we will first need to create a new
project with a simple scene. In my case, I created a simple Universal Render
Pipeline (URP) project and added a new empty scene to this project.&lt;/p&gt;
&lt;p&gt;Because the main focus of this write-up is how to utilise the geometry shader,
I opted to create simple unlit shaders as a basis. This means we can remove
the directional light within the scene, as it is not utilised in the materials.&lt;/p&gt;
&lt;p&gt;Next I added a simple script to my camera to take care of the rotation 
behaviour. It might well be possible to achieve the same effect with built in
tooling, however because I am a software engineer by trade, this was the path
of least resistance to me.&lt;/p&gt;
&lt;p&gt;The script has the following content:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/1d6e286997a09c9d59e367bd8791cb42.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;As you can see it is rather trivial. Within the update script we update the 
rotation of the transform of the object is attached to and rotate it around
the z-axis located at the world center. We can adjust the speed of the rotation
with the &lt;code&gt;timePerRotation&lt;/code&gt; field.&lt;/p&gt;
&lt;p&gt;We can slap this on our, and it wil automatically rotate around the world
center (which can be observed by looking at the transformation component)
in the inspector while the game is running.&lt;/p&gt;
&lt;p&gt;Lastly, we make some minor changes to the camera, to ensure you will have 
a scene identical to mine.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The position of the camera is set to: (0, 10, -18)&lt;/li&gt;
&lt;li&gt;The rotation of the camera is set to: (30, 0, 0)&lt;/li&gt;
&lt;li&gt;The Background Type i set to 'Solid Color'&lt;/li&gt;
&lt;li&gt;The background is set to the following hexadecimal value: 292D33&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This should now give you an empty scene with a dark blue-ish background.
In the following sections we will get to the juicy bits, and actually 
start implementing our simple grid.&lt;/p&gt;
&lt;h2&gt;Rendering thick lines with the help of a geometry shader&lt;/h2&gt;
&lt;p&gt;The first step in generating our simple 2D Grid is to visualise the lines of 
the grid. This step will consist out of two steps, generating a simple plane
consisting of vertices connected with lines and then writing our shader to
give the lines of the plane some width. The shader should work for any mesh
consisting of lines, however for the sake of simplicity we will just generate
a simple grid to visualise.&lt;/p&gt;
&lt;h3&gt;Generating a simple plane as geometry&lt;/h3&gt;
&lt;p&gt;The easiest way to represent a grid is as a collection of lines connecting 
vertices. This is exactly how will represent our geometry. First we create a 
new script that will contain our mesh generation code. Once this is created
let's move to your favourite IDE and get coding.&lt;/p&gt;
&lt;p&gt;First we provide some fields which can be customised in the editor:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/4da98624980b704239db00a7e19e070a.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Shader: The shader to render the geometry with&lt;/li&gt;
&lt;li&gt;Total Width: the total width of our plane&lt;/li&gt;
&lt;li&gt;Total height: the total height of our plane&lt;/li&gt;
&lt;li&gt;Subdivision X: The number of subdivisions in the local x-axis&lt;/li&gt;
&lt;li&gt;Subdivision Y: The number of subdivisions in the local y-axis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next we will create the necessary components on our game object when starting
the player:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/408e3dda00b7a51d5f3eb7bd1102686e.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;A mesh renderer linking to our selected shader&lt;/li&gt;
&lt;li&gt;A Mesh filter containing our mesh&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of this will be generated upon starting, thus adjusting the values while in
play mode will not influence the created geometry at all. This is an acceptable
limitation in my opinion, for the sake of simplicity.&lt;/p&gt;
&lt;p&gt;Next we have a method that generates the actual mesh. A mesh consists of a set 
of vertices and indices defining the topology. These are respectively generated 
in the aptly named &lt;code&gt;GenerateVertices&lt;/code&gt; and &lt;code&gt;GenerateIndices&lt;/code&gt; methods. The 
vertices are basically spaced out over the plane according to the user 
specified values. The indices define the lines between the vertices. These are 
set with the &lt;code&gt;SetIndices&lt;/code&gt; method, and specified as being &lt;code&gt;MeshTopology.Lines&lt;/code&gt;.
This will ensure that in our shader the lines are interpreted as lines, and not
triangles.&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/663fd5bb130979ed04568102c301d504.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;When rendered with a default unlit shader, this has the following result:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/lines.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;The full script can be found &lt;a href="https://gist.github.com/BeardedPlatypus/14ef94e2cf5a7adb2dc7ddb9c76e42e8"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Giving lines depth with the geometry shader&lt;/h3&gt;
&lt;p&gt;Now that we have our lines, as shown above we can take a look at how to give 
these lines a width. Before we start doing anything, first create an unlit 
shader if you had not done so before, and assign it to the &lt;code&gt;GenerateLines&lt;/code&gt; 
lines script. &lt;/p&gt;
&lt;p&gt;Next we will enable the geometry shader. For this we need to make the following
changes to the default unlit shader:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define a &lt;code&gt;_Width&lt;/code&gt; float property in the properties&lt;/li&gt;
&lt;li&gt;Add the &lt;code&gt;#pragma geometry geom&lt;/code&gt; line&lt;/li&gt;
&lt;li&gt;Rename &lt;code&gt;v2f&lt;/code&gt; to &lt;code&gt;v2g&lt;/code&gt; to indicate that the vertex dat is passed to the geom shader&lt;/li&gt;
&lt;li&gt;Add a new struct &lt;code&gt;g2f&lt;/code&gt; which will hold the data being passed from the geom shader to the frag shader&lt;/li&gt;
&lt;li&gt;Add a new &lt;code&gt;void geom&lt;/code&gt; method to the shader, under the &lt;code&gt;v2g vert&lt;/code&gt; method&lt;/li&gt;
&lt;li&gt;Change the &lt;code&gt;v2g vert&lt;/code&gt; shader to hand over the world coordinate vertex data instead of clip space&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This should lead to code similar to the following:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/69fd0926c005ba95297780f9cfc3f0fa.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;Before discuss how to generate lines with width, let's first look at the 
declaration of the geometry shader:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/69a9399f4c29d17459dbec37d5e9532f.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;geom&lt;/code&gt; is defined by the pragma we added at the beginning of the shader. 
Next we indicate that the geometry shader will receive line primitives 
consisting of two vertex shader structs, this is our input data. Lastly we 
define a &lt;code&gt;TriangleStream&amp;lt;g2f&amp;gt;&lt;/code&gt; will be used to output our triangles consisting 
of three vertex each defined by a &lt;code&gt;g2f&lt;/code&gt; struct. This is necessary because the
geometry shader itself is a void, and thus does not directly output elements.
Instead it uses a stream to do so. Lastly, we define the attribute 
&lt;code&gt;maxvertexcount&lt;/code&gt; on the geometry shader. This specifies the maxmimum of new 
primitives being generated by this shader. As we will see in the next 
paragraph, this will be 6 in our case.&lt;/p&gt;
&lt;p&gt;If we want to give our lines depth, we will need to represent each line as a
quad, or two triangles. These quad will be the same length as the provided 
line, and will have a width of &lt;code&gt;_Width&lt;/code&gt;. In order to generate the vertices
of the quad we can adopt the following strategy given the following points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We will only generate a two dimensional grid, thus we do not need to worry about the y-axis location of the end points&lt;/li&gt;
&lt;li&gt;The new vertices will lay perpendicular to the existing two points at +/- half the defined width&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is illustrated in the following figure:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/lines_illustration.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;Rotating a vector (x, y) by 90 degrees, corresponds with the vector (y, - x). 
We can define the direction of the line and the corresponding offset as&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/337ed23961bf7cae5473500c94f83776.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;Next we can define the four new vertices as follows:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/63903e04278ed419d1d552d52a38ed79.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;With the vertices of a line defined, we can generate the two triangles, as shown in the figure:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/ec39ef3001d562286a1e38ec9e97a176.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;You see that we generate two triangles, each closed with a &lt;code&gt;RestartStrip&lt;/code&gt; call. 
Further note that the order of the vertices is important. If the wrong order is
specified it might flip the normal in the opposite direction than what you are
expecting. If you do not see anything, it might be the case that you need to 
look at the grid from underneath instead of on top. In order to fix this you 
want to flip the order of vertices (switch the first and third vertices).&lt;/p&gt;
&lt;p&gt;When finished you should see the following when starting the game:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/lines_with_thickness.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;The full code for the shader can be found &lt;a href="https://gist.github.com/BeardedPlatypus/303b43347b271f44cd88526cf568cc9d"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Rendering points as circles with the help of a geometry shader&lt;/h2&gt;
&lt;p&gt;When the lines are thin enough and the lines are basically a uniform grid, then
current geometry and shader set up might be sufficient. However, when grid 
is less uniform, and if the lines are thicker, you might start seeing small 
artifacts at the points where the lines do not correctly flow into each other.
We can remedy this by rendering the points explicitly. Furthermore, we can 
actually emphasise the vertices of our plane, by rendering our points with a
larger diameter than our line width, ensuring they show up separately.&lt;/p&gt;
&lt;p&gt;In order to render the points, we will again first create a script that creates
the geometry at runtime, and then the shader that transforms the geometry into
the actual circles.&lt;/p&gt;
&lt;h3&gt;Generating the vertices of a plane&lt;/h3&gt;
&lt;p&gt;Generating the geometry for the point shader is even simpler than the lines. 
It mostly looks similar to the generation of the geometry of the lines. The
vertices are generated completely the same as in the line geometry script, and
could in theory be shared between the two, however for this particular example
I thought that would be overkill. The two major differences are in the indices.
First, the generation of the indices is simpler, basically each vertex will
now be a point primitive, thus we only need a range equal to the size of the
vertices and we need to specify that the mesh topology consists of points this
time.&lt;/p&gt;
&lt;p&gt;In order to create this script we will do the same as with the lines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add a new empty game object&lt;/li&gt;
&lt;li&gt;Create a new script and assign it to the empty game object&lt;/li&gt;
&lt;li&gt;Add the script code defined &lt;a href="https://gist.github.com/BeardedPlatypus/615db9f5bf0cd5bda1632559749be3f3"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you can see, the code is basically a simplified version of the line creation
code. Do note the &lt;code&gt;SetIndices&lt;/code&gt; line though.&lt;/p&gt;
&lt;p&gt;If we temporarily disable the lines object, and create a new unlit shader, we
should see the following:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/points.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;h3&gt;Turning the points into circles with a given radius&lt;/h3&gt;
&lt;p&gt;With the geometry set up, we can again set up a simple shader to turn our points
into circles. In order to do this, it is easiest to start with a copy of your 
lines shader and remove the content of the geometry function. Next we adjust
the function declaration to the following:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/0d09f5282614ea8150beb20b5d12e6e2.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, this time we use point primitives, which consist of only a single
primitive.&lt;/p&gt;
&lt;p&gt;Next we can take a look how to generate a circle. In our case, we want to create a
simple approximation of a circle consisting of a number of triangles. In order to 
generate such an approximation we will generate 'n' number of vertices, where n is
any number greater than 3, for example 12. In order to fill the vertices, we will
create 'n-2' triangles, thus the &lt;code&gt;maxvertexcount&lt;/code&gt; is set to '(n-2)*3', or in the
case of 12, to 30.&lt;/p&gt;
&lt;p&gt;With the initial definition out of the way let's define how we generate our circles&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The vertex provided by the vertex shader is going to be the centre of our circle.&lt;/li&gt;
&lt;li&gt;The width is going to be equal to our diameter of the circle&lt;/li&gt;
&lt;li&gt;The circles will be generated in two dimensions, thus we will again take over the y-axis value of the original vertex&lt;/li&gt;
&lt;li&gt;The vertices generated by our geometry shader are going to be evenly spread out on a circle of half width&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With that knowledge out of the way, we can define n vertices offsetted from our 
centre vertex. The offset will be equal to the vector (0.5 * width, 0) rotated
by the index of the vertex times '360 degrees / n' around. Lastly, we can fill
our circle by creating triangles from a single vertex, and walking over the 
other vertices, as illustrated here:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/points_illustration.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;If we put this into code we will get the following:&lt;/p&gt;
&lt;div style="margin: 2em 0em 2em 0em;"&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/51444f0528f9b65ad4a00979d5497700.js"&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;p&gt;In tihs code snippet we first define our initial vertex, which will act as our 
anchor for the triangle strip. Next we generate the other vertices, and append
them within the for-loop to generate our triangles. The full shader code can be
found &lt;a href="https://gist.github.com/BeardedPlatypus/47910ac6559ef126e9ade5fb9113f9ac"&gt;here&lt;/a&gt;. 
In order to ensure the points render on top, I have moved them 0.0001 above the
y axis position of the grid lines.&lt;/p&gt;
&lt;p&gt;When set up correctly it should look like this:&lt;/p&gt;
&lt;p align='center'&gt;&lt;img align='center' src='https://github.com/BeardedPlatypus/media-storage/blob/main/blog/geometry-shader/circles.png?raw=true' width='100%'&gt;&lt;/p&gt;

&lt;p&gt;When we enable the lines again, we get the result as shown at the beginning, 
which completes our set up.&lt;/p&gt;
&lt;h2&gt;Final thoughts and next steps&lt;/h2&gt;
&lt;p&gt;With the grid completely set up, there are some avenues we could pursue further. 
The next step I will most likely take is combining the scripts into a single 
component, that will generate a complete grid and corresponding geometry. Once
this is done, it should be easier to create a script that can generate a grid 
from provided data.&lt;/p&gt;
&lt;p&gt;Another interesting next step would be to investigate how to visualise data
associated with the grid on the grid itself. While I have not tested it, I
believe it should be possible to associate colours with the primitives and
use vertex colours to generate the appropriate styling. If we want to render
data on top of the faces, we would need to extend the geometry, and render 
the faces as well.&lt;/p&gt;
&lt;p&gt;In either case, we have a solid foundation to further extend our grid from.
Thank you for reading, and I am looking forward to seeing you again in the 
future.&lt;/p&gt;</content></entry><entry><title>SonarCloud: Static Code Analysis in a C++ project.</title><link href="beardedplatypus.github.io/sonarcloud-static-code-analysis-in-a-c-project.html" rel="alternate"></link><published>2019-12-27T00:00:00+01:00</published><updated>2019-12-27T00:00:00+01:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-12-27:beardedplatypus.github.io/sonarcloud-static-code-analysis-in-a-c-project.html</id><summary type="html">&lt;p&gt;As part of my pacman project's Continuous Integration (CI), I have set up 
SonarCloud as a static code analysis tool. This was done to get a bit better
insight in the state of my code base, as well as a way to get feedback and
improve my C++ knowledge. Because …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As part of my pacman project's Continuous Integration (CI), I have set up 
SonarCloud as a static code analysis tool. This was done to get a bit better
insight in the state of my code base, as well as a way to get feedback and
improve my C++ knowledge. Because this ended up being slightly more work than 
I initially had hoped, I will use this article to explain how I set up 
SonarCloud in conjunction with my pacman project. Hopefully this will both 
serve as a reminder to myself and a simple tutorial for you.&lt;/p&gt;
&lt;p&gt;For a tl;dr, the DevOps pipeline that is set up can be found &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/7127d4b26988f3442b811a2225583e775bc7b0d9/sonarcloud-pipeline.yml"&gt;here&lt;/a&gt;. 
The full pacman project can be found &lt;a href="https://github.com/BeardedPlatypus/PacMan"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;At my current place of work, we use SonarQube to get insight in the quality of
our code. It provides a simple, insightful dashboard that highlights
bugs, code smells, code coverage and duplication. This allows developers to 
gain insight in the quality of the code they have committed. To me personally,
I love the way certain bad habits get highlighted, and I get forced to fix 
them. Often, there exists some exotic intricacy within the language I am not 
aware of, or I am using in a wrong way, and SonarQube will highlight it 
mercilessly. This allows me to learn and become a better coder in my opinion, 
in much the same way as I learn from ReSharper suggestions.&lt;/p&gt;
&lt;p&gt;At work, I was not involved in setting this tool up, so I did not have any 
experience, before I set it up for this project. It turned out to be a bit more
of a struggle than I would like to admit, so a write up was in order.&lt;/p&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;It might be useful to give a bit more context in how my project is currently 
set up. This could help evaluate whether the approach I took could be useful 
for your project.&lt;/p&gt;
&lt;p&gt;My &lt;a href="https://github.com/BeardedPlatypus/PacMan"&gt;pacman clone&lt;/a&gt; is developed in (modern) C++, with the help of the &lt;a href="https://www.libsdl.org/download-2.0.php"&gt;SDL2 library&lt;/a&gt;
for rendering the sprites. It is build with visual studio 2019 / MSBuild. 
Testing is done with VSTest and the google test adapter. gtest and gmock are 
used to write the unit tests. All of these libraries are installed through 
vcpkg. The whole thing is wrapped into an installer with the help of WiX.&lt;/p&gt;
&lt;p&gt;On the CI side of things, I use Azure DevOps to automate my build and test 
processes. So far, I have been positively surprised by Azure DevOps, and the 
convenience of running these things in the cloud is great. I use boards to 
track my work items, and pipelines to run my build processes. The repository is
hosted on GitHub, since I use that as my portfolio.&lt;/p&gt;
&lt;h1&gt;Setting up SonarCloud&lt;/h1&gt;
&lt;h2&gt;Pre-requisites&lt;/h2&gt;
&lt;p&gt;I am going to assume that the you have set up the following accounts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://sonarcloud.io/"&gt;SonarCloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/services/devops/"&gt;Azure DevOps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A online repository, from a service like Azure Repos, GitHub, GitLab, 
  BitBucket etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am also going to assume you are vaguely familiar with Azure Pipelines. I will
try to explain the different steps added to my pipelines to the best of my 
abilities, but I might gloss over steps not related to SonarCloud. I have also
used a bit of python to glue everything together, so be prepared for that too.
Finally, as always with my articles, take it with a bit of salt. I am by no 
means an expert in any of this, so there might be better ways to do some of
these steps. If you find something that works better, by all means go for it!&lt;/p&gt;
&lt;h2&gt;A basic setup&lt;/h2&gt;
&lt;p&gt;I started off by following the basic SonarCloud / Azure DevOps tutorial found
&lt;a href="https://docs.microsoft.com/en-us/labs/devops/sonarcloudlab/index"&gt;here&lt;/a&gt;.
However, I ran into some problems due to using C++ instead of C#. So the 
following text will be significantly inspired by the previously mentioned 
tutorial, however, it is adapted to how I got it to work with C++.&lt;/p&gt;
&lt;p&gt;With that out of the way, let's get started, and set up our initial SonarCloud
pipeline.&lt;/p&gt;
&lt;h3&gt;Adding the SonarCloud extension&lt;/h3&gt;
&lt;p&gt;Navigate to the &lt;a href="https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarcloud"&gt;SonarCloud extension&lt;/a&gt;
on the Visual Studio Marketplace, and install it into your project. This 
will add the required tasks into your online pipeline editor, and will save
us from a bunch of fiddling with the command line.&lt;/p&gt;
&lt;h3&gt;Creating a new pipeline&lt;/h3&gt;
&lt;p&gt;Once you have the extension installed, there are two roads you could take.
Either you could integrate the SonarCloud steps into an existing pipeline,
possibly as a separate stage or job, or you could add an additional 
pipeline. I opted for the latter for the sake of simplicity, but do not let
that stop you from integrating it with an existing pipeline.&lt;/p&gt;
&lt;p&gt;I created a new "Starter pipeline", using my pacman repository as the source,
and called it &lt;code&gt;sonar-cloud-pipeline.yml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;At the time of writing, this leads to the following yaml file:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/a7d555bbaeb68791cf8646d812b10748.js"&gt;&lt;/script&gt;

&lt;p&gt;The current content is not particularly relevant for our use case, so I
replaced it with the basic build steps for building my pacman application:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/5d417571a1ff3c00b4a046366745e9a6.js"&gt;&lt;/script&gt;

&lt;h3&gt;Adding the SonarCloud tasks&lt;/h3&gt;
&lt;p&gt;SonarCloud will analyse your solution by applying various metrics to
find problems with your code. It does so by static analysis, and it
will gather the necessary data to do this while you compile your program. &lt;/p&gt;
&lt;p&gt;So in order to get our analysis up and running we need to take the following 
steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First we need to configure SonarCloud to analyse our compile process.&lt;/li&gt;
&lt;li&gt;Then we need to compile our solution.&lt;/li&gt;
&lt;li&gt;Next we need SonarCloud to analyse the results of compiling our program.&lt;/li&gt;
&lt;li&gt;Finally, the results of the analysis need to be pushed to the SonarCloud server, such that they become available in the SonarCloud dashboard.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This means we will have to add the following three tasks to our pipeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SonarCloudPrepare@1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SonarCloudAnalyze@1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SonarCloudPublish@1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Where &lt;code&gt;SonarCloudPrepare@1&lt;/code&gt; will be placed before our build process, and the
other two will be placed after. &lt;/p&gt;
&lt;h3&gt;SonarCloud Prepare&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;SonarCloudPrepare@1&lt;/code&gt; task will require some some setting up, which the
assistant will walk you through. First, select the "Prepare Analysis 
Configuration". We will see several options we need to configure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SonarCloud Service Endpoint&lt;/li&gt;
&lt;li&gt;Organization&lt;/li&gt;
&lt;li&gt;Choose the way to run the analysis&lt;/li&gt;
&lt;li&gt;Project Key&lt;/li&gt;
&lt;li&gt;Project Name&lt;/li&gt;
&lt;li&gt;Project Version&lt;/li&gt;
&lt;li&gt;Additional Properties (under advanced)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Starting off with the SonarCloud Service Endpoint. We will need to configure
the end point within our SonarCloud project, and link it to our Azure DevOps
project. First we will generate a SonarCloud token.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Navigate to your project on &lt;a href="www.sonarcloud.io"&gt;sonarcloud.io&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Go to "My account" (under your profile avatar in the top right corner).&lt;/li&gt;
&lt;li&gt;Go to the "Security" tab, between "Profile" and "Notifications".&lt;/li&gt;
&lt;li&gt;Under "Generate Tokens", add a new recognisable name. This name will not be
   used, but it does serve as a reminder for what the token was generated, such
   that you know whether you want to keep it later, or revoke it. As such, I 
   would recommend giving it a readable name, in my case it is called "PacMan 
   Azure DevOps".&lt;/li&gt;
&lt;li&gt;Press the "Generate" button and copy the token. (Note, by closing this tab
   you will not be able to copy it anymore, and you will have to revoke the 
   previous tab, I would recommend either putting it in a notepad temporarily
   or leaving this tab open until you are done setting this up.)&lt;/li&gt;
&lt;li&gt;With the token generated, go to your Azure DevOps project settings. (This can
   be done by selecting the little cog icon next to your Azure project name).&lt;/li&gt;
&lt;li&gt;Select the "Service connections" link under "Pipelines".&lt;/li&gt;
&lt;li&gt;Press "New service connection" in the top right corner.&lt;/li&gt;
&lt;li&gt;Find and click the "SonarCloud" entry in the list and press "Next".&lt;/li&gt;
&lt;li&gt;Add the token in the "SonarCloud Token" field and press verify.&lt;/li&gt;
&lt;li&gt;Fill in a readable name in the "Service connection name", this is the name
   we will add to "SonarCloud Service Endpoint" field in our yaml file.&lt;/li&gt;
&lt;li&gt;Optionally add a description.&lt;/li&gt;
&lt;li&gt;Press "Verify and save". Now we are ready to add this to our yaml.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With the SonarCloud Service Endpoint configured, go ahead and add the name
you provided in step 11 within the field of "SonarCloud Service Endpoint".&lt;/p&gt;
&lt;p&gt;In the "Organization" and "Project Key" fields, add your SonarCloud 
"Organization Key" and "Project Key" respectively. These can be found in the 
second column of your SonarCloud project dashboard.&lt;/p&gt;
&lt;p&gt;Since I am integrating it with MSBuild, the scanner mode is selected to be
"MSBuild". "Project Name" is set to the same as my project, and for the
sake of simplicity I have set my "Project Version" to 1.0, though you can
set this to the respective version of your software, and it will be displayed
correctly in your project dashboard.&lt;/p&gt;
&lt;p&gt;Finally press add, to add this task to your pipeline yaml. Make sure it gets
placed before the build task.&lt;/p&gt;
&lt;h3&gt;SonarCloud Analyse and Publish&lt;/h3&gt;
&lt;p&gt;Next we will add the &lt;code&gt;SonarCloudAnalyze@1&lt;/code&gt; and &lt;code&gt;SonarCloudPublish@1&lt;/code&gt; tasks
after our VSBuild step. Find the "Run Code Analysis" and "Publish Quality
Gate Result" tasks in your assistant, and add them to your yaml. I did not
modify the polling time out myself, and just left it at 5 minutes.&lt;/p&gt;
&lt;p&gt;The pipeline will now look like this:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/15124ef12556e4c660fccf263774d2e4.js"&gt;&lt;/script&gt;

&lt;h3&gt;Adding the build wrapper&lt;/h3&gt;
&lt;p&gt;In an ideal world, this should be enough to get SonarCloud to work. 
Unfortunately, this being a C/C++ project, we need to do some additional 
work. &lt;/p&gt;
&lt;p&gt;When this pipeline is run it gives an error containing the following
statement:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/2a9b78e380a6fbe37c42eac36ce34d57.js"&gt;&lt;/script&gt;

&lt;p&gt;In order for it to work, we will need to wrap our MSBuild process in the 
build wrapper process. The executable to do this can be obtained from 
the SonarCloud website &lt;a href="https://sonarcloud.io/static/cpp/build-wrapper-win-x86.zip"&gt;here&lt;/a&gt;.
I opted to put this directly into my repository, because I am lazy, and had
some trouble getting it to download correctly as a build step. There is nothing
stopping you from adding it as a download step instead though.&lt;/p&gt;
&lt;p&gt;Either way, after obtaining it you should have a path to the executable. For 
the sake of convenience let's wrap this in a variable, add the following line
to your variables section of your yaml:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/a91cca95daf675a5f2a87c5f79774795.js"&gt;&lt;/script&gt;

&lt;p&gt;We can also add our future output directory, as mentioned in the error message,
as a variable, such that we only have to define it once:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/95ac4f7c86a011a40516c8cc11a9e3c2.js"&gt;&lt;/script&gt;

&lt;p&gt;With that out of the way, the next step is to modify our &lt;code&gt;VSBuild&lt;/code&gt; step. Unfortunately,
our regular &lt;code&gt;VSBuild&lt;/code&gt; step does not have a way to wrap it in our build wrapper, or 
I have not found a way to do this. Instead, I have changed the &lt;code&gt;VSBuild&lt;/code&gt; task to 
a power shell task, and defined the command myself. It is not pretty, but it works.&lt;/p&gt;
&lt;p&gt;The new command becomes:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/6a11fc85f5bf2514095b929eb22642d9.js"&gt;&lt;/script&gt;

&lt;p&gt;Let's break down what happens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First we define call our build wrapper executable stored in &lt;code&gt;buildWrapperExe&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;We set the output path of any results to the &lt;code&gt;buildWrapperOutputDir&lt;/code&gt; we defined earlier.&lt;/li&gt;
&lt;li&gt;We call the MSBuild exe stored in &lt;code&gt;msBuildExe&lt;/code&gt;, this is the regular MSBuild stored on the Azure agent.&lt;/li&gt;
&lt;li&gt;We make it compile our solution, and set the configuration and platform similarly to a regular &lt;code&gt;VSBuild&lt;/code&gt; task.&lt;/li&gt;
&lt;li&gt;We also specified the option &lt;code&gt;-nologo&lt;/code&gt; to skip printing the logo, such that our output log stays a bit clean.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the build wrapper configured, the only thing we need to set is the build 
wrapper output directory within our &lt;code&gt;SonarCloudPrepare&lt;/code&gt; task. This will allow
the &lt;code&gt;SonarCloudAnalyze&lt;/code&gt; step to pick up on our results, and actually produce
the right results. We do this by adding the following line to the additional 
properties of SonarCloud:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/6a069c0f47ef664cfd45e2bfc5633f0c.js"&gt;&lt;/script&gt;

&lt;p&gt;Lastly, I have set up my SonarCloud pipeline to run once every three hours if
a commit has taken place. This will ensure I am not running my pipeline 
unnecessarily. If I do happen to need immediate feedback I tend to kick off my 
pipeline by hand anyway. In order to do this, I changed the beginning of my
pipeline yaml to the following:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/4c8cc75f6ac2b4476b08910e2fca6d1a.js"&gt;&lt;/script&gt;

&lt;p&gt;If you have followed along diligently and I did not make any mistake, you 
should have the following yaml code:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/5d884475fc5949fa384105077d24b62b.js"&gt;&lt;/script&gt;

&lt;p&gt;With all that out of the way we should have our basic SonarCloud pipeline up
and running, and we should be able to inspect the results in our SonarCloud
project dashboard. Up next, we will take a look how to connect our final metric,
code coverage.&lt;/p&gt;
&lt;h2&gt;Adding code coverage&lt;/h2&gt;
&lt;p&gt;The last metric to set up within SonarCloud is the code coverage. I will not go
into detail about how to unit test, or why it is a good thing, enough articles
are written on these topics already, but I will add that if you are not writing
unit tests, I wholeheartedly encourage you to start doing so. If you are not
interested in the code coverage, then this is all you need to do to start using
SonarCloud, and I wish you happy code smell hunting!&lt;/p&gt;
&lt;p&gt;Within SonarCloud we can display the code coverage metric. Once set up, 
SonarCloud will show you the overall code coverage of your solution, as well as
the coverage on newly added line, giving you a good sense of how well tested
your new code is. Furthermore, it provides a convenient interface to show which
parts of the code are untested, and let's you sort files containing uncovered 
lines in greater detail. A very useful feature in my opinion.&lt;/p&gt;
&lt;p&gt;As mentioned previously, within the pacman project I use gtest / gmock to do my
testing in combination with the google test adapter and VSTest. When running 
the VSTest task on Azure Pipelines, you can enable measuring code coverage. 
This will add a &lt;code&gt;.coverage&lt;/code&gt; file somewhere on your agent. You could use this
&lt;code&gt;.coverage&lt;/code&gt; file within visual studio to show the uncovered pieces of code.
With a bit of tweaking, we can also use this data within SonarCloud.
However, the &lt;code&gt;.coverage&lt;/code&gt; file is not supported out of the box,
and we will need to export it to an &lt;code&gt;.xml&lt;/code&gt; file, before it will play nice.&lt;/p&gt;
&lt;h3&gt;Producing a .coverage file&lt;/h3&gt;
&lt;p&gt;The first step into getting the code coverage set up in SonarCloud, is ensuring
the &lt;code&gt;.coverage&lt;/code&gt; gets produced. As mentioned before, we can configure a VSTest
task to produce these files. Within my pacman project, I already have a CI 
pipeline in place that runs my test suite. Instead of rerunning the whole test
suite just to produce the code coverage, I figured it would be less wasteful to
reuse the data gathered during this CI pipeline. As such, the following text 
will assume you have two pipelines, one CI and one SonarCloud pipeline. The 
SonarCloud pipeline will reuse the artefacts from the CI pipeline. It should 
only be a minor inconvenience to modify the SonarCloud pipeline, to run the
VSTest itself. With that out of the way, let's set up the &lt;code&gt;.coverage&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;We can enable the code coverage by adding the following option to our VSTest task:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/3a2a51925a819794c96d863dea87bc21.js"&gt;&lt;/script&gt;

&lt;p&gt;This will ensure our &lt;code&gt;.coverage&lt;/code&gt; file gets produced. &lt;/p&gt;
&lt;p&gt;With the current iteration
of the VSTest task this file will be placed in the test results folder, located
in the TEMP folder of the Azure Agent. This location has changed in between
versions of the VSTest task already, therefor it would not necessarily be smart
to rely on an absolute path. Instead, we will configure our VSTest task to output
the &lt;code&gt;.coverage&lt;/code&gt; file in a specific location. To do so, we need to create a 
&lt;code&gt;.runsettings&lt;/code&gt; that specifies the output location, as shown below:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/7bfdab6e73c1fc3718ee20fce9a6841f.js"&gt;&lt;/script&gt;

&lt;p&gt;Where &lt;code&gt;some/Directory&lt;/code&gt; is the path where the coverage files will be placed in.
In order to keep all of this as flexible as possible, I opted to generate this
&lt;code&gt;.runsettings&lt;/code&gt; file during execution with a python script, which takes the path
it will generate as an argument. This way we do not need to make any 
assumptions about the file system, and instead can set this in our pipeline yaml.&lt;/p&gt;
&lt;p&gt;The script to do this can be located &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/64ecbff3512e6205a95b02712f0ad2f73e37d978/tools/location_runsettings.py"&gt;here&lt;/a&gt;. 
I will not go over the script line by line, I hope it is mostly 
self-explanatory. But I will explain the rough idea. The script itself takes
two arguments, first the path at which we want to construct the new 
&lt;code&gt;.runsettings&lt;/code&gt; file, and the path we want to output the &lt;code&gt;.coverage&lt;/code&gt; file to. 
These arguments are parsed with the help of the argparse library, in the 
&lt;code&gt;parse_arguments&lt;/code&gt; function. Within the &lt;code&gt;run&lt;/code&gt; function, we first construct
the output directory and the parent directory of the &lt;code&gt;.runsettings&lt;/code&gt; file, if
they do not exist yet. Lastly we generate the &lt;code&gt;.runsettings&lt;/code&gt; file at the 
specified path with the use of the &lt;code&gt;RUNSETTINGS_TEMPLATE&lt;/code&gt; in the &lt;code&gt;generate_runsettings&lt;/code&gt;
function.&lt;/p&gt;
&lt;p&gt;We can integrate this script by adding the following two tasks to our pipeline
yml anywhere before the VSTest task:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/3f5d0f1d88d90f542da4ca153761b70a.js"&gt;&lt;/script&gt;

&lt;p&gt;This will first set up the required Python 3 interpreter, and then execute the 
python script linked earlier. The mentioned arguments are stored in the 
variables &lt;code&gt;codeCoverageLocationRunsettings&lt;/code&gt; and &lt;code&gt;testResults&lt;/code&gt;. These have been
defined in the variables section of our pipeline yaml, and will be reused in
subsequent steps.&lt;/p&gt;
&lt;p&gt;Finally, we need to modify our VSTest task slightly to make use of our generated
&lt;code&gt;.runsettings&lt;/code&gt; file. As part of the &lt;code&gt;inputs&lt;/code&gt; of the VSTest add the following line:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/7f43ff99a44380aed360163bd7106a24.js"&gt;&lt;/script&gt;

&lt;p&gt;This will ensure that the &lt;code&gt;.coverage&lt;/code&gt; files are generated in &lt;code&gt;testResults&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Passing the .coverage files between pipelines&lt;/h3&gt;
&lt;p&gt;This section deals with interaction between the two pipelines, if you are 
running the VSTest task within your SonarCloud pipeline, you can safely skip
this section.&lt;/p&gt;
&lt;p&gt;Now that we have our &lt;code&gt;.coverage&lt;/code&gt; files generated in a known location, we can
publish them as pipeline artefacts, and download them in the SonarCloud 
pipeline. Publishing files as an artefact is done through the 
&lt;code&gt;PublishPipelineArtifact&lt;/code&gt; task, or "Publish Pipeline Artifacts" in your Azure
Pipelines assistant. Go ahead and select it from the list in your assistant.
We have the following fields that we can configure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File or directory path&lt;/li&gt;
&lt;li&gt;Artifact name&lt;/li&gt;
&lt;li&gt;Artifact publish location&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the directory path we want to use the &lt;code&gt;testResults&lt;/code&gt; variable. The name
can be anything you like, however we will use this name within the SonarCloud
pipeline, so I would not recommend going all out on it. Lastly, the Artifact 
publish location should be set to "Azure Pipelines" (unless you have a really
good reason to upload it to a fileshare, then knock yourself out).&lt;/p&gt;
&lt;p&gt;This should lead to the following code (note, I added a simple display name
to make my build steps look nice in the log):&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/feda76e5c449bb37a50d0a90047a3bb7.js"&gt;&lt;/script&gt;

&lt;p&gt;Next, we will download the coverage pipeline artefact within our SonarCloud
pipeline. This can be done with the &lt;code&gt;DownloadPipelineArtifact&lt;/code&gt; task, or 
"Download Pipeline Artifacts" in your assistant. We have a bunch of options
to configure here.&lt;/p&gt;
&lt;p&gt;First set the "Download artifacts produced by" to "Specific run", 
which will open up some additional options. The project should be set
to the project that contains your CI pipeline, and the "Build pipeline"
should be set to this specific pipeline. In my case these are "PacMan"
and "Build and Test PacMan" respectively. For "Build version to download"
pick "Latest". You could add a specific tag that should be present to
use to select a specific run, but I have not bothered with this.&lt;/p&gt;
&lt;p&gt;Finally we need to set the "Artifact name", "Matching patterns", and
the "Destination directory". For "Artifact name" pick the name that
you gave the artifact in the previous step (&lt;code&gt;coverage&lt;/code&gt; in the snipped above).
Since we are only interested in the &lt;code&gt;.coverage&lt;/code&gt; file, I have specified 
my "Matching patterns" to &lt;code&gt;**/*.coverage&lt;/code&gt;, this will look recursively
in all the folders of my artefact for any file ending with &lt;code&gt;.coverage&lt;/code&gt;.
As a final step, download the files somewhere on your agent. In my case
I put it in a variable called &lt;code&gt;coverageDownloadLocation&lt;/code&gt;. This should 
put a task in your yaml comparable to:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/322a9de24d68c20e9f12cf1d2451ca71.js"&gt;&lt;/script&gt;

&lt;p&gt;Next up, we will convert the &lt;code&gt;.coverage&lt;/code&gt; file to &lt;code&gt;.xml&lt;/code&gt; and feed it into
the SonarCloud analysis.&lt;/p&gt;
&lt;h3&gt;Converting the .coverage file&lt;/h3&gt;
&lt;p&gt;Converting the &lt;code&gt;.coverage&lt;/code&gt; files to &lt;code&gt;.xml&lt;/code&gt; is a reasonably easy process, once
you have figured out how to do it. The path to figuring it out though, is
painful and filled with perils, so hopefully you can learn from my mistakes
and it will be a breeze for you. First and foremost let me state, that if you
want to use paths with spaces in your python and command line scripts, make sure
you use double quotes, &lt;code&gt;"&lt;/code&gt;, and not single quotes, &lt;code&gt;'&lt;/code&gt;. Yes ... it took me longer
than I would like to admit to figure that out. With that out of the way, let's
look at how we can convert &lt;code&gt;.coverage&lt;/code&gt; files in to something usable by SonarCloud.&lt;/p&gt;
&lt;p&gt;If my understanding is correct, the &lt;code&gt;.coverage&lt;/code&gt; is basically a binary blob of
code coverage information, which can be used by Visual Studio to give you an
indication of your code coverage. Unfortunately, it does not work out of the 
box for SonarCloud. This means we need to convert it to an &lt;code&gt;.xml&lt;/code&gt; file which will be
usable. There are various ways of doing this, but the easiest I have found is 
to use the &lt;code&gt;codecoverage.exe&lt;/code&gt; provided with Visual Studio Enterprise, i.e. the
Visual Studio version that is installed on the Azure agents.&lt;/p&gt;
&lt;p&gt;When we run the following command, it will convert the &lt;code&gt;.coverage&lt;/code&gt; into an &lt;code&gt;.xml&lt;/code&gt;
file:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/8970b5d2b2588d0df38bcc3f9ad097d2.js"&gt;&lt;/script&gt;

&lt;p&gt;Where input and output can basically be any name you want it to be. &lt;/p&gt;
&lt;p&gt;Because I did not want to hard code the location of the &lt;code&gt;codecoverage.exe&lt;/code&gt;,
and I do not know the &lt;code&gt;.coverage&lt;/code&gt; file names without running actually running
the pipeline, I ended up writing another python script to dynamically resolve
these things. The script can be found &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/3d723576abfbf06da38007984b37b9696efd89a6/tools/convert_coverage.py"&gt;here&lt;/a&gt;.
Again, I will not go over the script line by line, but I will explain the rough
set up. The script takes one argument, the folder in which the &lt;code&gt;.coverage&lt;/code&gt; files
are located. It then resolves the &lt;code&gt;codecoverage.exe&lt;/code&gt; path by searching for it in
the Visual Studio folder of the agent. It will then copy the &lt;code&gt;.coverage&lt;/code&gt; files from 
the specified path to the current working directory. Lastly, it will convert the
recently copied files from &lt;code&gt;.coverage&lt;/code&gt; to &lt;code&gt;.xml&lt;/code&gt; using the &lt;code&gt;codecoverage.exe&lt;/code&gt;.
Once done, the current working directory should contain the relevant &lt;code&gt;.xml&lt;/code&gt; files
(and the original &lt;code&gt;.coverage&lt;/code&gt; files). &lt;/p&gt;
&lt;p&gt;This script is ran in the same way as before, by adding two python tasks (after
the download pipeline artifacts task):&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/baa6114cb11198c6ba6f5dc4f8b3ca74.js"&gt;&lt;/script&gt;

&lt;p&gt;We set up the argument and the working directory with the appropriate variables
again defined in the variable section of the yaml. If you are interested in 
seeing the output, you could publish the defined working directory as an artefact,
such that they can be downloaded and inspected.&lt;/p&gt;
&lt;h3&gt;Modifying the SonarCloud tasks&lt;/h3&gt;
&lt;p&gt;The final step to wrap up our SonarCloud setup, is to use the newly generated
&lt;code&gt;.xml&lt;/code&gt; files within our analyses. For this we need to add one more line to our
&lt;code&gt;extraProperties&lt;/code&gt;:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/56f930fe91c676045407cf2d582eb8b2.js"&gt;&lt;/script&gt;

&lt;p&gt;Where &lt;code&gt;coverageFiles&lt;/code&gt; is defined as:&lt;/p&gt;
&lt;script src="https://gist.github.com/BeardedPlatypus/0ceefdd5f9319e395ef41c608a5f9ef4.js"&gt;&lt;/script&gt;

&lt;p&gt;Which says all the &lt;code&gt;.xml&lt;/code&gt; files within the location where we generated our &lt;code&gt;.xml&lt;/code&gt;
files. This should ensure that SonarCloud takes into account the code coverage,
and you can keep an eye on maintaining that 80%+ metric!&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This guide turned out to be slightly longer than I originally intended, but if
you followed along, and I did not make any mistakes, you should have a pipeline
looking similar to &lt;a href="https://github.com/BeardedPlatypus/PacMan/blob/7127d4b26988f3442b811a2225583e775bc7b0d9/sonarcloud-pipeline.yml"&gt;my SonarCloud pipeline&lt;/a&gt;. Which should provide you with a dashboard similar to
&lt;a href="https://sonarcloud.io/dashboard?id=BeardedPlatypus_PacMan"&gt;my pacman project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope this made the process of setting up SonarCloud for a C++ project slightly
easier for you. Thank you for reading! And if you have any comments, suggestions, 
or questions, let me know!&lt;/p&gt;</content></entry><entry><title>TeamCity: Adding a custom report to your build configuration</title><link href="beardedplatypus.github.io/teamcity-adding-a-custom-report-to-your-build-configuration.html" rel="alternate"></link><published>2019-08-03T00:00:00+02:00</published><updated>2019-08-03T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-08-03:beardedplatypus.github.io/teamcity-adding-a-custom-report-to-your-build-configuration.html</id><summary type="html">&lt;p&gt;Recently, I took some time to add a bit of custom reporting to the teamcity 
project we use at work. I did not have much experience with this before, and
honestly, I was quite surprised with the ease to do so. As a reference for 
myself, and hopefully for you …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, I took some time to add a bit of custom reporting to the teamcity 
project we use at work. I did not have much experience with this before, and
honestly, I was quite surprised with the ease to do so. As a reference for 
myself, and hopefully for you as well, in this short article I will detail how I
achieved this.&lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;To give a little bit of background, at the time of writing, I work at Deltares,
a knowledge institute on Water. I work on one of the GUIs for our water 
modelling software. We use TeamCity on our build server. The TeamCity project 
contains a bunch of configurations doing different tests and builds our 
installers.&lt;/p&gt;
&lt;p&gt;One of these configurations is our Acceptance Tests configuration. This
configuration runs a bunch of models, made within deltares, that our considered
representative of models that can be made. As such, if the software runs 
correctly for these models, it should run correctly for all models.
The test configuration is set up to run a set of NUnit tests that load these
models, does a few checks and runs the models. Arguably this is not an ideal
set up, but it is the process we have at the moment. &lt;/p&gt;
&lt;p&gt;Each model run produces a log file, that describes what has happened, as well as
any warnings and errors. This file is of interest when these acceptance models
start failing. However, the current set up removes all of these files. We want
to be able to inspect these files, to check them for any warnings or errors that
might point to mistakes in our code (or the kernel code).&lt;/p&gt;
&lt;p&gt;A first step to achieve that, would be to save these files in a separate 
artifact. Which allows us to download them, and inspect them. But why stop 
there? We could easily extend this, to allow us to inspect the files from within
TeamCity, which lowers the barrier to do so, quite a bit. We can do so with 
custom reports, hence this article.&lt;/p&gt;
&lt;h1&gt;Bring out the custom reports!&lt;/h1&gt;
&lt;h2&gt;What do we need?&lt;/h2&gt;
&lt;p&gt;A custom report is basically an additional tab, in which we can display 
additional information, which is produced as part of our build procedure. This
can be anything, really. It can be used to track performance times, it can be 
used to build a custom coverage tool. All we need to add this custom report to
our TeamCity configuration, is an html file. This html file will be hosted in
the TeamCity report tab, &lt;a href="https://confluence.jetbrains.com/display/TCD10/Including+Third-Party+Reports+in+the+Build+Results"&gt;see this documentation&lt;/a&gt;.
You can even put your html file in an archive like zip, and just refer to it.
Something we will do. &lt;/p&gt;
&lt;p&gt;In order to make this report available to our tab, we do need to add it to our
artifacts. As such, the only thing you need is an html file that is published 
as an artifact.&lt;/p&gt;
&lt;h2&gt;Optionally adding an additional build step&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Feel free to skip this part if you do not need to add a new build step that executes a python tool&lt;/em&gt;
As mentioned before, the html file should be produced as part of the build
process. If none is produced at the moment, it might be necessary to add another
build step to your configuration, which is responsible for building the actual 
report.&lt;/p&gt;
&lt;p&gt;In my case, the tests produce a bunch of log files, one per model run. These
are saved within the check-out folder, such that they will not be immediately
deleted. However, no report html is generated automatically. To do this, I have
written a small python script, that collects the content of the log files and 
stuffs them inside a simple html file. This html file is the one we want to 
publish. Lastly, the script zips the whole set of log files and the index
file into a single zip, for easy download.&lt;/p&gt;
&lt;p&gt;In order to execute this script, a build step is added to the configuration: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First navigate to the build configuration, in which we want to produce the
     report. Press the &lt;em&gt;Edit Configuration Settings&lt;/em&gt; link in the top right corner
     next to the &lt;em&gt;run&lt;/em&gt; and &lt;em&gt;actions&lt;/em&gt; button. From here, select the &lt;em&gt;Build Steps&lt;/em&gt;
     link on the left hand side of the screen.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We are presented with several buttons that allow us to modify our build
     configuration. We want to press &lt;em&gt;Add build step&lt;/em&gt; to create our new build
     step at the end of our configuration. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You are presented with a wizard to set up your build step. In our case, we
     want to execute a python script, which we will do from the Command Line, 
     thus we select &lt;em&gt;Command Line&lt;/em&gt; as our runner type, did not see that coming
     did you? &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Choose an appropriate &lt;em&gt;Step name&lt;/em&gt;, this will show up in the build steps
     page we were on earlier. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In our case we want to execute the python script regardless of whether the
     test runs were successfull, so instead of &lt;em&gt;If all previous steps finished successfully&lt;/em&gt;
     we can select, &lt;em&gt;Even if some of the previous steps failed&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can leave the &lt;em&gt;Working Directory&lt;/em&gt; empty if you are running from the
   check-out folder, otherwise you want to set the folder in which you want
   to execute your command line script. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can also leave the &lt;em&gt;Custom script&lt;/em&gt; bit, and move on to filling in the
     build script content.  &lt;/p&gt;
&lt;p&gt;On our build server we have installed &lt;code&gt;conda&lt;/code&gt;, which we will use to quickly
 generate a python3 environemnt, which we will use to execute the script.
 Then we will run the script, and finally we will remove the environment 
 again, because it is always good to clean up after yourself.&lt;br&gt;
 This leads to the following script:  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;create&lt;/span&gt; &lt;span class="n"&gt;-y&lt;/span&gt; &lt;span class="n"&gt;-n&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="n"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;5&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;activate&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;path/to/your/script.py&amp;quot;&lt;/span&gt; &lt;span class="no"&gt;[withOptionalArguments]&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;deactivate&lt;/span&gt;  
&lt;span class="n"&gt;CALL&lt;/span&gt; &lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;remove&lt;/span&gt; &lt;span class="n"&gt;-y&lt;/span&gt; &lt;span class="n"&gt;-n&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;someEnvName&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;-all&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now got our reporting tool set up, which will produce our output somewhere
in our check-out folder (hopefully).&lt;/p&gt;
&lt;h2&gt;Adding the report to the artifacts&lt;/h2&gt;
&lt;p&gt;Assuming we have our reports being generated somewhere within the check-out 
folder. We will have to add them to our artifacts. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;First navigate to the build configuration to which we want to add our report
     tab. Then press &lt;em&gt;Edit Configuration Settings&lt;/em&gt; next to the &lt;em&gt;Run&lt;/em&gt; and &lt;em&gt;Actions&lt;/em&gt;
     buttons.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On the page that opens there should be an &lt;em&gt;Artifact paths&lt;/em&gt; section. We can 
     add the path to our report here, such that it gets released as an artifact.
     The given path should be relative to the check-out folder.&lt;br&gt;
     In our case, the report is made in an &lt;em&gt;Artifacts&lt;/em&gt; folder, and is called
     &lt;em&gt;dia_report.zip&lt;/em&gt; (naming has never been one of my strong suits). Thus our
     artifact becomes.  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Artifacts\dia_report.zip&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;If you already have a run that produced the report, you can also press the
 little tree button next to the text field, to select it, producing the 
 correct path.  &lt;/p&gt;
&lt;p&gt;With that done, you should see your report in the next run as an artifact.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Adding a custom build report&lt;/h2&gt;
&lt;p&gt;The last step is adding the actual custom report tab to the build configuration.
This is not done within the build configuration, something I found a bit counter
intuitive, but instead should be done at the project root. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;&amp;lt;root project&amp;gt;&lt;/code&gt; and select &lt;em&gt;Edit Project Settings&lt;/em&gt; in the 
     top right corner.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;em&gt;Report Tabs&lt;/em&gt; page through the menu on your left hand side.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are two options, you can create a new project report tab, or a build
     report tab. Project report tabs will show on the project, and use the 
     artifacts produced by one of the build configurations within the project.
     The build tab is what we want. It allows us to set a path to a report html.
     Any build configuration that contains an html file within its artifacts at 
     this specific path, will have this build tab.&lt;/p&gt;
&lt;p&gt;As such, press the &lt;em&gt;Create new build report tab&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now set the &lt;em&gt;Tab Title&lt;/em&gt; and the &lt;em&gt;Start page&lt;/em&gt; of your report html. 
     Press save, and voila! We should have ourselves a custom report tab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Within this article we added a simple custom report tab to one of our TeamCity
build configurations. We can use this to provide easily provide additional 
test information directly within our build server. The process itself is 
rather painless, and for the most part intuitive. All things considered, 
I am really happy how this turned out, and I hope it helps you in your 
process as well.&lt;/p&gt;
&lt;p&gt;Hopefully see you next time!&lt;/p&gt;</content></entry><entry><title>Setting up Continuous Delivery for your static website.</title><link href="beardedplatypus.github.io/setting-up-continuous-delivery-for-your-static-website.html" rel="alternate"></link><published>2019-07-21T00:00:00+02:00</published><updated>2019-07-21T00:00:00+02:00</updated><author><name>Maarten Tegelaers</name></author><id>tag:None,2019-07-21:beardedplatypus.github.io/setting-up-continuous-delivery-for-your-static-website.html</id><summary type="html">&lt;p&gt;In this article we will take a short look how to set up continuous delivery for
a simple static website (my own, woo!) with Azure DevOps. Once set up, any 
commit to both content and the theme should trigger the right builds that end up
building and pushing the changes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this article we will take a short look how to set up continuous delivery for
a simple static website (my own, woo!) with Azure DevOps. Once set up, any 
commit to both content and the theme should trigger the right builds that end up
building and pushing the changes to a github pages website. For my own website
I use pelican, however, the content in this article should be easily adjustable
to any static website!&lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Lately, I have been wanting to start writing and posting some blog articles 
again. Having an active blog has been something I want for quite a while (I 
think my original github pages was created afew years ago), however I never took
the time to properly finish any of the articles, as polishing my own personal 
projects has never been a strong suit of mine. &lt;/p&gt;
&lt;p&gt;These past few weeks I have been working on some small personal projects that I
want to document in some fashion, such that I can understand what I did in the
future. I figured this would be an excellent opportunity to create some blog 
articles that are worth sharing. &lt;/p&gt;
&lt;p&gt;When I looked at this dusty bit of webspace, I noticed however, that it had not
aged as well as I had hoped. So as would be expected from my procrastinating 
nature, I decided to first dust it off, give it a lick of paint, before doing 
the thing I actually want to do, which is write the blog articles.&lt;/p&gt;
&lt;p&gt;As part of the dusting off, I figured I would automate some steps that felt 
like a drag. Because the website is a generated static website, whenever I made 
a change to either the the theme or the content, I would need to run all the 
compilation steps by hand, and then push the results to my github pages 
repository. Lazy as I am, this cannot be of course. &lt;/p&gt;
&lt;p&gt;As I have been working with Azure DevOps lately in some other personal projects, 
I figured it would be a good choice to automate the compilation with. These 
build steps can then be executed as part of a build pipeline running on the 
servers of microsoft. And because of that idea, you can now read this article!&lt;/p&gt;
&lt;h1&gt;Project Configuration&lt;/h1&gt;
&lt;p&gt;The main configuration of my website can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config"&gt;this repository&lt;/a&gt;
As mentioned before, the website is created with pelican, a static website 
generator written in python. There are a bunch of alternatives on the market 
(Jekyll comes to mind but also newer generators like Hugo), however I picked 
pelican because of its python support, a language I am already quite comfortable
with. As much as I enjoy learning new languages, in this case I wanted something
I could get up and running without struggling too much (of course being me, I 
did struggle with it, but that's besides the point). &lt;/p&gt;
&lt;p&gt;Besides pelican I have used Gulp to compile my own crafted theme, and do a little
bit of optimisation. The examples within this blog post will thus be focused on
these technologies. However, it should be rather trivial to adapt the examples 
to any other static website generator. In this section I will quickly go over 
the project structure,and how the technologies are set up. For further detail 
I would refer you to the documentation of the specific tools, as the focus of
the rest of the article is on how to set up the Azure DevOps pipelines.&lt;/p&gt;
&lt;h2&gt;Folder Structure&lt;/h2&gt;
&lt;p&gt;The static website basically consists of three parts, the theme, which can be
found in &lt;a href="https://github.com/BeardedPlatypus/rubber-squid"&gt;this repository&lt;/a&gt;, 
the content, which can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-content"&gt;this repository&lt;/a&gt;
and lastly the configuration files, which can be found in 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config"&gt;this repository&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;After completing a full run of the compilation of the website we will have 
the following (simplified) directory structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Base                  # config git repository
├───content           # content git repository
│   ├───articles
│   └───pages
├───plugins           # plugins used by pelican
├───production        # output folder of pelican
├───theme
│   └───rubber-squid
│       ├───static
│       └───templates
└───website_dist      # output of gulp postPelican
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, the content folder is checked out as separate repository in the
config folder, and the theme is checked out in the theme folder. I could have 
set this up with the help of git submodules, however I have not done this yet,
and for the current purposes, this set up suffices.&lt;/p&gt;
&lt;h2&gt;Pelican&lt;/h2&gt;
&lt;p&gt;Pelican is configured through the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/pelicanconf.py"&gt;pelican.conf&lt;/a&gt;
and the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/publishconf.py"&gt;publish.conf&lt;/a&gt;.
Within these files things like the theme, names etc are specified. In addition
to the default pelican, I also use the summary plugin, which helps creating the
summaries for the blog index page. I have modified this slightly to remove any
links from within the summaries.&lt;/p&gt;
&lt;p&gt;When pelican is properly installed, the static website can be generated through
the following command: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pelican content -s publishconf.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will create all the html pages based on your content, theme and 
configuration in the &lt;code&gt;production&lt;/code&gt; folder. The contents of this folder
could be uploaded immediately to a github pages repository, and it 
would be available for viewing. However we can do a little bit better and 
optimise the result of pelican with some javascript magic.&lt;/p&gt;
&lt;h2&gt;Gulp&lt;/h2&gt;
&lt;p&gt;When I created the previous incarnation of this website, I did not know anything
about web optimisation, since then I have learned some new tricks and figured 
I wanted to incorporate them. Building my website now has a pre and post step
besides the pelican compile step.&lt;/p&gt;
&lt;p&gt;Before we can build the website, we first need to compile the theme, or more 
specifically, the sass files, such that we have some css that pelican can use.
As mentioned before, once the compilation is done, we can then further optimise
the output a bit by calling some other javascript magic.&lt;/p&gt;
&lt;p&gt;Both of these steps are managed by &lt;a href="https://gulpjs.com/"&gt;Gulp&lt;/a&gt;.
I set up a simple  workflow, based upon 
&lt;a href="https://css-tricks.com/gulp-for-beginners/"&gt;this tutorial&lt;/a&gt; to do so.&lt;/p&gt;
&lt;p&gt;The pre step at the moment of writing merely compiles the sass files through the
following gulp command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gulp prePelican
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The post pelican step collects all css files, concatenates them, and minimises them,
and puts them in a &lt;code&gt;website_dist&lt;/code&gt; folder. It also copies over any of the html, 
js, and feed files. I currently have not set up the minimisation of the js file, 
as I already did this in a separate step, when I created my own js. However in the
future there is a good chance I will add this. This step can be executed as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gulp postPelican
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The steps themself are set up in the &lt;code&gt;gulp.js&lt;/code&gt; file of the 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/gulpfile.js"&gt;config repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that I am nowhere near experienced with any of this, so take this 
set up with a grain of salt, and do your own research in order to find a set up 
that works well for you!&lt;/p&gt;
&lt;h1&gt;Compile the website on Azure DevOps&lt;/h1&gt;
&lt;p&gt;With the extremely short primer out of the way, let's take a look at the actual
build configuration. In essence, we want to do 4 steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compile the theme&lt;/li&gt;
&lt;li&gt;compile pelican&lt;/li&gt;
&lt;li&gt;optimise the pelican output&lt;/li&gt;
&lt;li&gt;push it all to the github pages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in the following section we will take a look at each of these steps, if however
you just want to see the configuration, it can be found 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/azure-pipelines.yml"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the sake of brevity, I am going to assume you already have a project set up, 
and can know where to find the add build pipeline button. If you do not know this,
I recommend going over the documentation of Azure DevOps, it should not take long to
set up.&lt;/p&gt;
&lt;h2&gt;Setting up the Pelican Components&lt;/h2&gt;
&lt;p&gt;In order to set up our pipeline, we need to make use of python and javascript. We will
start with python, and then move on to the nodejs component.&lt;/p&gt;
&lt;p&gt;The main build line should be based in our config repository, as this one will hold all
the information to actually build the website. As such, I selected GitHub as my source 
of my code, and then the config repository. Since we want to use python for our pelican
application build, I started out with the python package configuration as base. &lt;/p&gt;
&lt;p&gt;We only need a single python version, as we only build our website once. Furthermore,
at the time of writing I did not include any python testing, so I removed this step to.
This leaves us with the following yml code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;# Python package&lt;/span&gt;
&lt;span class="cp"&gt;# Create and test a Python package on multiple Python versions.&lt;/span&gt;
&lt;span class="cp"&gt;# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:&lt;/span&gt;
&lt;span class="cp"&gt;# https:&lt;/span&gt;&lt;span class="c1"&gt;//docs.microsoft.com/azure/devops/pipelines/languages/python&lt;/span&gt;

&lt;span class="nl"&gt;trigger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;

&lt;span class="nl"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;vmImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="nl"&gt;strategy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;Python37&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nl"&gt;version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;3.7&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="nl"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;UsePythonVersion&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Use&lt;/span&gt; &lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="n"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;upgrade&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt;
    &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;dependencies&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;First it defines a trigger, this means that whenever a commit is made on the 
branches listed under it, this specific build will trigger. Since we only want
to actually build and push or website when we make a definitive commit, we can
leave this on master.&lt;/p&gt;
&lt;p&gt;Next some strategies are defined. If we had an actual python package to test, 
we might want to do that for different versions. However, we only need one 
version of python, so we can remove all but the 3.7 version, as this is the 
latest.&lt;/p&gt;
&lt;p&gt;In the following step it gets the specific python version, and then 
installs our requirements.txt file. The requirements file specifies which packages
need to be installed. For pelican we need both the pelican package and the markdown
package, as such it looks liks this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Markdown==3.1.1
pelican==4.0.1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once these steps have executed, we have our python installation ready to use, and
we can add the pelican compile step.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- script: |
    pelican content -s publishconf.py
  displayName: &amp;#39;Pelican Compile&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, it merely executes our pelican command, as we defined it the previous
section. The &lt;code&gt;displayName&lt;/code&gt; will be shown in the summary of Azure DevOps, and makes
debugging a bit easier, so I try to give it a relevant name, but you could always
change or even remove it.&lt;/p&gt;
&lt;p&gt;We can add this part right after the python bit and execute it. Unfortunately. This
code does not work yet, as we do not have our data to act on. Before we set this up
though, let's add the javascript bit to our code.&lt;/p&gt;
&lt;h2&gt;Setting up the nodejs / npm components&lt;/h2&gt;
&lt;p&gt;If we instead had started with Node.js pipeline, our template would have looked like 
this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;# Node.js&lt;/span&gt;
&lt;span class="cp"&gt;# Build a general Node.js project with npm.&lt;/span&gt;
&lt;span class="cp"&gt;# Add steps that analyze code, save build artifacts, deploy, and more:&lt;/span&gt;
&lt;span class="cp"&gt;# https:&lt;/span&gt;&lt;span class="c1"&gt;//docs.microsoft.com/azure/devops/pipelines/languages/javascript&lt;/span&gt;

&lt;span class="nl"&gt;trigger&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;

&lt;span class="nl"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nl"&gt;vmImage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="nl"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NodeTool&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;run&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It uses the same pool and trigger as our python script, and contains the steps to
install Node.js and npm. Therefore we can just copy these install steps to the 
configuration we are setting up.&lt;/p&gt;
&lt;p&gt;We can remove the npm run build step, as we are not building an actual Node.js 
application, we merely want it to install gulp. Once we call the npm
install step, all the packages from our &lt;code&gt;package.json&lt;/code&gt; are installed. For this
website this is basically gulp, and some supporting plugins, see 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/package.json"&gt;here&lt;/a&gt;.
After running the install, we can use gulp to compile our team and optimise the
output of pelican.&lt;/p&gt;
&lt;p&gt;Since we defined all our pre-pelican steps in one command, the step in our configuration
becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- script: |
    gulp prePelican
  displayName: &amp;#39;Pre-Pelican Compile&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and the post pelican step becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- script: |
    gulp postPelican
  displayName: &amp;#39;Post-Pelican Compile&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We put these commands before and after our pelican step:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="nf"&gt;task:&lt;/span&gt; &lt;span class="n"&gt;UsePythonVersion&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Use&lt;/span&gt; &lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="n"&gt;$&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;upgrade&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt;
    &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;dependencies&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;task&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NodeTool&lt;/span&gt;&lt;span class="mi"&gt;@0&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;versionSpec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Install&lt;/span&gt; &lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;npm&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;gulp&lt;/span&gt; &lt;span class="n"&gt;prePelican&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Pre&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;pelican&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;publishconf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;gulp&lt;/span&gt; &lt;span class="n"&gt;postPelican&lt;/span&gt;
  &lt;span class="nl"&gt;displayName&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Pelican&lt;/span&gt; &lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With that set up, we are basically all ready to execute our compilation process.
Next up, getting the data.&lt;/p&gt;
&lt;h2&gt;Checking out the additional repositories&lt;/h2&gt;
&lt;p&gt;In order to get our data from github, we basically need to clone our content and
theme repositories. Since I was having some troubles with the script task, I opted
to use the powershell task. This task basically gives access to a powershell instance
in your configuration, and allows you to run a variety of commands. &lt;/p&gt;
&lt;p&gt;Since git comes pre-installed, we do not have to worry about it, and can just use
git commands in our powershell task.&lt;/p&gt;
&lt;p&gt;There might be reasons why you want to keep your theme and content into private
repositories, in order to clone these repositories you will need to authenticate
yourself. Ideally, you would use some token based way to authenticate yourself,
however I have not come around to do so in my own pipeline, so instead we can alse  use 
basic authentication for this within github. In order to do so we need to specify 
our URL as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="err"&gt;\\&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nl"&gt;account_name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;account_pw&lt;/span&gt;&lt;span class="nv"&gt;@github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;account&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;/&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;repository&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;git&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We do not want to leak this information in our build logs. Therefore we are going 
to use private variables, 
&lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;amp;tabs=yaml%2Cbatch"&gt;as microsoft recommends&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thus our clone steps then become:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- powershell: |
    $url = &amp;quot;github.com/BeardedPlatypus/rubber-squid.git&amp;quot;
    $url = &amp;quot;:$env:GITHUB_PW@$url&amp;quot;
    $url = &amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;
    $url = &amp;quot;https://$url&amp;quot;
    git clone $url &amp;quot;theme/rubber-squid&amp;quot;
  displayName: &amp;#39;Check out - Rubber Squid Theme&amp;#39;
  env:
    GITHUB_ACCOUNT: $(github.profile)
    GITHUB_PW: $(github.password)

- powershell: |
    $url = &amp;quot;github.com/BeardedPlatypus/personal-website-content.git&amp;quot;
    $url = &amp;quot;:$env:GITHUB_PW@$url&amp;quot;
    $url = &amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;
    $url = &amp;quot;https://$url&amp;quot;
    git clone $url content
  displayName: &amp;#39;Check out - Blog Content&amp;#39;
  env:
    GITHUB_ACCOUNT: $(github.profile)
    GITHUB_PW: $(github.password)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first steps are done to build our URL as described above. I had 
some trouble getting this to work too be honest, and this ended up
working correctly, so I decided to stick with it.&lt;/p&gt;
&lt;p&gt;Once we have build our URL, we can clone our repositories. Because
pelican expects them in a specific place relative to our working 
directory, we add the folder we want them in.&lt;/p&gt;
&lt;p&gt;I have added these steps before I even install python or Node.js.
The chance that these steps fail as opposed to the install steps
is greater, and we rather fail earlier than later.&lt;/p&gt;
&lt;h2&gt;Getting some artifacts&lt;/h2&gt;
&lt;p&gt;Now that we have all our compilation steps set up, once we run
our build confiration, we should have a nice &lt;code&gt;website_dist&lt;/code&gt; folder,
containing our whole website. Before we push this to our github 
pages, let's add some steps to publish this as an artifact as well.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="nf"&gt;task:&lt;/span&gt; &lt;span class="n"&gt;CopyFiles&lt;/span&gt;&lt;span class="mi"&gt;@2&lt;/span&gt;
  &lt;span class="nl"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nl"&gt;contents&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;website_dist&lt;/span&gt;&lt;span class="cm"&gt;/**&amp;#39;&lt;/span&gt;
&lt;span class="cm"&gt;    targetFolder: $(Build.ArtifactStagingDirectory)&lt;/span&gt;
&lt;span class="cm"&gt;  displayName: &amp;#39;Artifacts - Copy&amp;#39;&lt;/span&gt;

&lt;span class="cm"&gt;- task: PublishBuildArtifacts@1&lt;/span&gt;
&lt;span class="cm"&gt;  inputs:&lt;/span&gt;
&lt;span class="cm"&gt;    pathToPublish: $(Build.ArtifactStagingDirectory)&lt;/span&gt;
&lt;span class="cm"&gt;    artifactName: websiteContents&lt;/span&gt;
&lt;span class="cm"&gt;  displayName: &amp;#39;Artifacts - Publish&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will output our &lt;code&gt;website_dist&lt;/code&gt; for us to inspect, and ensure
the website was generated correctly. We could further extend this
to also publish the output of pelican, or the first gulp step 
for example. This could help with debugging.&lt;/p&gt;
&lt;h2&gt;Pushing the content to github pages&lt;/h2&gt;
&lt;p&gt;In order to push our content to our github pages repository, we
need to do the following things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clear our repository&lt;/li&gt;
&lt;li&gt;Add the output of our postPelican step&lt;/li&gt;
&lt;li&gt;Commit the changes&lt;/li&gt;
&lt;li&gt;Push the content&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to clear out the content of our current github pages
repository, we can create an empty check out of our repo, in
the &lt;code&gt;website_dist&lt;/code&gt; folder. This can be achieved with the 
following step:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- powershell: |
    git clone --no-checkout &amp;quot;https://github.com/BeardedPlatypus/BeardedPlatypus.github.io&amp;quot; website_dist
  displayName: &amp;#39;Check out - BeardedPlatypus.io&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--no-checkout&lt;/code&gt; flag will ensure we do not check out any files.
If we were to commit this as is, it would clear our whole repository.
We want to put this step before our &lt;code&gt;postPelican&lt;/code&gt; step, such that the
folder is still empty (otherwise git will complain).&lt;/p&gt;
&lt;p&gt;Now, once we have passed the &lt;code&gt;postPelican&lt;/code&gt; step, we can actually 
add all the files generated, commit, and push them. The step to
do this looks as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- powershell: |
    git config user.email &amp;quot;$env:USER_EMAIL&amp;quot;
    git config user.name &amp;quot;$env:USER_NAME&amp;quot;

    git add *
    git commit -m &amp;quot;Automated update: $(Build.BuildNumber)&amp;quot;

    $url = &amp;quot;github.com/BeardedPlatypus/BeardedPlatypus.github.io.git&amp;quot;
    $url = &amp;quot;:$env:GITHUB_PW@$url&amp;quot;
    $url = &amp;quot;$env:GITHUB_ACCOUNT$url&amp;quot;
    $url = &amp;quot;https://$url&amp;quot;

    git push $url master
  displayName: &amp;#39;Update BeardedPlatypus.io&amp;#39;
  workingDirectory: website_dist
  env:
    GITHUB_ACCOUNT: $(github.profile)
    GITHUB_PW: $(github.password)
    USER_NAME: $(user.name)
    USER_EMAIL: $(user.email)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will execute this step in the &lt;code&gt;website_dist&lt;/code&gt; folder, as such
the &lt;code&gt;workingDirectory&lt;/code&gt; property of this step is pointing to this
folder. This will make it possible to refer just to the content
of this folder, and use the &lt;code&gt;--no-checkout&lt;/code&gt; local repository we 
just cloned.&lt;/p&gt;
&lt;p&gt;We start by setting up our &lt;code&gt;user.email&lt;/code&gt; and &lt;code&gt;user.name&lt;/code&gt; in order to be 
able to push our content to the repository in the final step. 
Next, we add and commit all the changes currently existing in the 
folder. Because the empty folder should already have been staged due
to the &lt;code&gt;--no-checkout&lt;/code&gt; flag, this should leave us with the files as 
they are in &lt;code&gt;website_dist&lt;/code&gt;. Furthermore, if there are no changes, 
git will just say everything is up to date, and finish up everything. &lt;/p&gt;
&lt;p&gt;After this, we again build our url, and push to the master branch of
the github pages repository. And with that we have our automatic 
deployment of our static website. &lt;/p&gt;
&lt;p&gt;The full &lt;code&gt;azure-pipelines.yml&lt;/code&gt; can be found 
&lt;a href="https://github.com/BeardedPlatypus/personal-website-config/blob/master/azure-pipelines.yml"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Triggering the build on content and theme changes&lt;/h2&gt;
&lt;p&gt;Unfortunately, we currently only trigger the build automatically when
we make a change to the configuration repository. Ideally, this repository
would change little, and most of the changes would be either to
the content or the theme. Thus, whenever we make a change to either 
of these repositories, we would need to do a manual run, which really
is not that much better than doing it by hand on your local machine.&lt;/p&gt;
&lt;p&gt;We can do better! As far as I know, we cannot directly add triggers
that go off once we make changes to these repositories, as one build
only works with one base repository. However, we can make our current
build trigger upon the completion of other builds. Therefor, we will
add some really simple build pipelines for these two repositories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;trigger:
- master

pool:
  vmImage: &amp;#39;ubuntu-latest&amp;#39;

steps:
- script: |
    echo &amp;quot;Theme has been triggered.&amp;quot;
  displayName: &amp;#39;Theme&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You could in theory extend these with some sanity or sanitary checks,
such that you do not kick off builds if you know something is wrong,
for now however I have set them up to merely do a simple echo and 
wrap up.&lt;/p&gt;
&lt;p&gt;Once we have set up these pipelines, you can add the completion of
these pipelines as triggers under the trigger settings of our
main build pipeline. Once that is done, our main build should 
trigger automatically. You can try it by running our newly added
pipeline once, and then check if our main gets triggered subsequently.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this article, we set up a simple Azure DevOps build to compile a static
website. We have gone over how to set up the python task to execute pelican,
and how to further optimise the results with the help of gulp. Finally, we
have set it up in such a way that changes to either the theme or content
repositories will ensure the website gets automatically updated and pushed
to the github pages repository.&lt;/p&gt;
&lt;p&gt;We could further extend this pipeline by adding additional optimisation. 
Furthermore, the build pipelines of both the theme and content could be
extended with additional checks, to ensure we only push when we can create
a valid website. For the time being though I am quite happy with the result.&lt;/p&gt;
&lt;p&gt;Thanks for reading, and I hope to see you soon again in another article!&lt;/p&gt;</content></entry></feed>